{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Adaptive_SNR_Testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neelabhro/Deep-Learning-based-Wireless-Communications/blob/main/Adaptive_SNR_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIoYASfEf7go"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKl9e4A0H1lk",
        "outputId": "0c1eeaf9-f39c-4ff7-a21d-0cfb19c48591"
      },
      "source": [
        "# magic command to use TF 1.X in colaboraty when importing tensorflow\n",
        "%tensorflow_version 1.x \n",
        "import tensorflow as tf                       # imports the tensorflow library to the python kernel\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)    # sets the amount of debug information from TF (INFO, WARNING, ERROR)\n",
        "import time\n",
        "import random\n",
        "print(\"Using tensorflow version:\", tf.__version__)\n",
        "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using tensorflow version: 1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiCDuiGqf7gr"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "import math\n",
        "pi = tf.constant(math.pi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrLsO1Nxf7g3"
      },
      "source": [
        "#### System parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spN0MeqFD7x-",
        "outputId": "4c306e22-9b18-401d-b3f7-39863376c43b"
      },
      "source": [
        "batch_size = 10000\n",
        "########## BIT FLIPPING ON\n",
        "#print(tr)\n",
        "#plt.plot(t, tr)\n",
        "T1 = random.randint(1, 10)\n",
        "T2 = random.randint(1, 10)\n",
        "M = 256\n",
        "t = np.linspace(0, 1, batch_size)\n",
        "triangle1 = signal.sawtooth(T1 * np.pi * 5 * t, 0.5)\n",
        "triangle1 = M/2*(triangle1)\n",
        "triangle1 = triangle1.clip(min=0)\n",
        "\n",
        "triangle2 = signal.sawtooth(T2 * np.pi * 5 * t, 0.5)\n",
        "triangle2 = M/2*(triangle2)\n",
        "triangle2 = triangle2.clip(min=0)\n",
        "\n",
        "triangle3 = triangle1 + triangle2\n",
        "#triangle3 = triangle3/15*(7)\n",
        "tr = triangle3\n",
        "#bins = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
        "bins = np.arange(M-1)\n",
        "tr = np.digitize(triangle3, bins, right=True)\n",
        "#plt.plot(t, triangle3)\n",
        "\n",
        "#tr = np.flip(tr)\n",
        "#print(tr)\n",
        "tr = np.floor(np.random.uniform(0,M, 10000))\n",
        "print(tr)\n",
        "#replacements = {0:7, 1:6, 2:5, 3:4, 4:3, 5:2, 6:1, 7:0}\n",
        "#replacements = {0:15, 1:14, 2:13, 3:12, 4:11, 5:10, 6:9, 7:8, 8:7, 9:6, 10:5, 11:4, 12:3, 13:2, 14:1, 15:0}\n",
        "rp1 = np.arange(M)\n",
        "rp2 = np.flip(np.arange(M))\n",
        "replacements = dict(zip(rp1,rp2))\n",
        "#print(rp2)\n",
        "replacer = replacements.get\n",
        "tr = ([replacer(n, n) for n in tr])\n",
        "\n",
        "#tr2 = ([replacer(n, n) for n in triangle3])\n",
        "print(tr)\n",
        "#plt.plot(t, tr)\n",
        "#plt.legend(['Input signal', 'Quantized and bit flipped'])\n",
        "\n",
        "#s_ind = np.empty(shape=(M,batch_size))\n",
        "s_ind = {}\n",
        "for j in range(M):\n",
        "  s_ind[j] = [i for i, x in enumerate(tr) if x == j]\n",
        "\n",
        "#print([tr[x] for x in s_ind_0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 60.  13.  49. ...  51.  31. 158.]\n",
            "[195, 242, 206, 90, 244, 239, 174, 208, 80, 190, 51, 243, 90, 89, 136, 6, 139, 255, 113, 162, 129, 21, 158, 230, 70, 189, 32, 60, 26, 29, 145, 58, 62, 123, 143, 88, 132, 64, 15, 65, 148, 130, 6, 195, 1, 254, 92, 120, 209, 170, 181, 93, 7, 230, 128, 74, 162, 122, 155, 67, 181, 206, 75, 152, 196, 218, 255, 197, 104, 32, 68, 160, 55, 51, 255, 246, 185, 252, 203, 43, 3, 83, 13, 219, 48, 46, 216, 229, 163, 241, 75, 112, 49, 30, 181, 115, 174, 119, 106, 220, 33, 255, 141, 29, 142, 190, 149, 18, 192, 249, 205, 224, 219, 91, 208, 234, 44, 216, 135, 98, 86, 67, 130, 26, 16, 31, 255, 73, 58, 13, 121, 22, 252, 162, 12, 206, 228, 238, 238, 236, 120, 111, 93, 90, 8, 215, 9, 138, 37, 55, 14, 90, 206, 63, 97, 182, 223, 147, 213, 65, 183, 179, 76, 168, 49, 146, 66, 54, 91, 245, 109, 220, 4, 170, 168, 88, 132, 79, 247, 22, 206, 213, 68, 34, 12, 80, 41, 5, 220, 41, 163, 48, 90, 103, 136, 190, 196, 42, 73, 41, 131, 66, 138, 250, 151, 216, 147, 254, 14, 84, 76, 45, 150, 238, 58, 159, 4, 25, 190, 191, 58, 176, 105, 46, 81, 25, 82, 208, 117, 224, 57, 243, 42, 157, 40, 88, 143, 9, 46, 116, 156, 128, 208, 232, 215, 219, 60, 153, 180, 95, 10, 190, 30, 56, 189, 185, 92, 245, 172, 131, 122, 67, 31, 56, 160, 240, 65, 201, 241, 196, 155, 177, 205, 127, 73, 78, 43, 97, 186, 53, 237, 161, 45, 0, 158, 96, 163, 160, 95, 208, 250, 101, 18, 4, 206, 168, 160, 239, 138, 173, 76, 10, 197, 49, 36, 98, 228, 129, 32, 41, 194, 192, 207, 154, 10, 206, 17, 184, 108, 150, 253, 73, 129, 119, 165, 172, 165, 106, 175, 217, 159, 110, 14, 55, 222, 156, 18, 232, 161, 40, 170, 148, 110, 58, 57, 26, 195, 222, 209, 215, 1, 34, 28, 236, 116, 214, 233, 137, 101, 48, 162, 250, 121, 224, 176, 142, 23, 61, 168, 1, 251, 4, 201, 159, 221, 143, 165, 35, 189, 64, 95, 196, 9, 178, 9, 223, 153, 79, 233, 113, 143, 111, 46, 227, 106, 176, 202, 77, 50, 228, 173, 241, 152, 218, 139, 108, 181, 194, 33, 229, 88, 227, 138, 157, 26, 213, 148, 51, 160, 153, 192, 1, 161, 102, 173, 27, 68, 65, 246, 37, 92, 96, 99, 20, 132, 132, 95, 20, 4, 188, 143, 100, 62, 2, 94, 41, 205, 53, 83, 90, 2, 0, 70, 114, 129, 106, 159, 238, 46, 25, 59, 208, 140, 131, 203, 54, 71, 119, 63, 13, 127, 139, 167, 185, 191, 11, 215, 46, 168, 32, 135, 31, 74, 14, 235, 167, 23, 25, 175, 75, 132, 109, 111, 206, 225, 244, 25, 122, 74, 246, 24, 245, 164, 178, 22, 85, 189, 128, 124, 7, 191, 77, 221, 111, 29, 102, 187, 225, 137, 107, 161, 95, 18, 26, 78, 108, 155, 224, 216, 80, 168, 132, 17, 139, 2, 100, 168, 124, 228, 12, 206, 140, 31, 30, 38, 233, 90, 228, 42, 70, 31, 202, 125, 80, 59, 235, 149, 105, 164, 205, 96, 4, 72, 13, 206, 44, 126, 73, 235, 22, 109, 165, 35, 73, 91, 128, 135, 32, 146, 211, 16, 91, 28, 91, 180, 46, 26, 48, 246, 137, 164, 233, 155, 190, 81, 130, 177, 172, 98, 7, 8, 188, 196, 74, 203, 8, 202, 236, 226, 49, 7, 25, 111, 82, 149, 201, 209, 177, 116, 162, 184, 216, 144, 48, 247, 246, 93, 129, 160, 129, 125, 194, 193, 135, 52, 219, 84, 106, 6, 76, 26, 62, 127, 217, 245, 113, 25, 122, 53, 92, 62, 184, 19, 141, 13, 226, 194, 191, 216, 131, 245, 49, 116, 216, 130, 224, 76, 213, 230, 88, 167, 2, 172, 183, 8, 84, 51, 207, 172, 150, 168, 109, 68, 102, 204, 41, 120, 165, 57, 153, 4, 140, 133, 71, 66, 143, 156, 185, 189, 186, 210, 133, 101, 4, 229, 44, 77, 164, 111, 140, 204, 52, 181, 58, 98, 104, 146, 216, 148, 77, 75, 218, 121, 34, 214, 196, 9, 129, 83, 83, 208, 196, 17, 128, 118, 161, 31, 113, 32, 238, 2, 69, 70, 200, 74, 35, 152, 78, 225, 214, 254, 56, 84, 71, 93, 52, 200, 85, 51, 94, 131, 19, 133, 85, 119, 221, 254, 137, 185, 14, 190, 144, 180, 216, 66, 204, 145, 54, 208, 113, 181, 106, 10, 182, 81, 65, 250, 144, 128, 97, 19, 136, 85, 208, 253, 195, 224, 145, 254, 115, 115, 11, 249, 233, 238, 162, 211, 177, 25, 166, 148, 149, 215, 166, 77, 192, 76, 164, 174, 109, 69, 4, 65, 217, 65, 13, 9, 178, 80, 134, 63, 40, 70, 33, 214, 11, 148, 0, 83, 1, 193, 14, 30, 127, 204, 130, 154, 12, 243, 68, 242, 139, 61, 157, 36, 175, 200, 21, 9, 176, 152, 10, 40, 215, 188, 77, 169, 245, 86, 221, 225, 61, 241, 155, 235, 2, 166, 91, 24, 167, 159, 73, 11, 219, 20, 109, 73, 1, 73, 62, 127, 215, 69, 9, 39, 229, 224, 141, 186, 134, 34, 121, 168, 216, 70, 124, 74, 130, 15, 1, 117, 208, 44, 189, 94, 252, 209, 103, 140, 180, 198, 24, 236, 211, 72, 107, 206, 248, 1, 14, 28, 7, 125, 79, 7, 82, 185, 128, 69, 136, 129, 57, 61, 72, 38, 135, 71, 176, 64, 160, 42, 173, 225, 166, 37, 147, 177, 119, 105, 160, 118, 96, 109, 222, 116, 121, 71, 77, 84, 187, 225, 207, 159, 44, 237, 135, 33, 53, 251, 210, 176, 21, 64, 147, 246, 218, 255, 208, 142, 163, 134, 119, 239, 37, 156, 156, 64, 156, 65, 103, 5, 191, 123, 141, 44, 222, 45, 218, 126, 69, 124, 165, 51, 45, 205, 76, 97, 184, 66, 103, 19, 242, 107, 73, 78, 7, 52, 22, 120, 30, 32, 95, 202, 48, 179, 237, 11, 142, 146, 110, 249, 216, 38, 9, 27, 129, 108, 102, 132, 110, 192, 250, 242, 237, 142, 253, 79, 217, 105, 77, 80, 46, 20, 181, 135, 222, 206, 53, 3, 135, 187, 67, 42, 191, 210, 183, 70, 250, 86, 204, 226, 148, 228, 86, 41, 243, 24, 122, 96, 150, 173, 228, 114, 93, 159, 215, 14, 234, 5, 95, 254, 252, 106, 109, 161, 77, 66, 167, 197, 33, 7, 123, 57, 144, 230, 146, 117, 32, 243, 145, 3, 23, 171, 93, 54, 191, 55, 89, 105, 85, 0, 167, 4, 181, 39, 120, 94, 194, 77, 137, 81, 59, 92, 71, 26, 88, 161, 140, 198, 254, 199, 110, 235, 144, 209, 17, 187, 171, 47, 238, 105, 233, 136, 243, 53, 155, 4, 41, 176, 215, 249, 183, 186, 139, 234, 91, 200, 172, 9, 188, 81, 221, 120, 7, 232, 45, 193, 146, 153, 190, 128, 221, 235, 216, 103, 151, 92, 148, 110, 152, 202, 53, 98, 8, 179, 173, 54, 66, 107, 38, 87, 65, 236, 109, 165, 179, 35, 224, 201, 65, 108, 78, 144, 213, 180, 149, 49, 199, 43, 193, 195, 197, 155, 67, 194, 39, 108, 1, 155, 158, 116, 91, 185, 198, 243, 158, 74, 146, 186, 252, 225, 94, 246, 202, 132, 165, 13, 225, 240, 229, 33, 22, 229, 187, 217, 238, 178, 175, 81, 24, 39, 37, 82, 240, 139, 198, 196, 75, 255, 4, 211, 4, 77, 169, 106, 60, 23, 38, 27, 223, 176, 250, 14, 208, 191, 116, 124, 152, 99, 45, 62, 139, 14, 23, 203, 47, 48, 173, 202, 82, 109, 168, 40, 69, 185, 201, 53, 162, 22, 149, 32, 227, 108, 217, 89, 185, 29, 96, 184, 98, 249, 133, 192, 66, 45, 249, 124, 4, 46, 222, 46, 176, 227, 189, 78, 153, 57, 215, 245, 209, 25, 227, 73, 238, 55, 179, 169, 90, 223, 7, 1, 115, 70, 207, 77, 104, 216, 216, 5, 117, 29, 115, 189, 65, 160, 167, 203, 238, 25, 126, 114, 33, 219, 201, 118, 235, 193, 147, 156, 190, 182, 149, 185, 184, 240, 219, 11, 180, 21, 248, 244, 39, 228, 250, 178, 59, 135, 248, 233, 191, 69, 203, 244, 64, 79, 169, 96, 236, 13, 100, 136, 136, 174, 90, 228, 62, 137, 212, 219, 83, 107, 62, 54, 8, 43, 45, 11, 83, 243, 176, 82, 66, 0, 135, 255, 188, 131, 177, 201, 241, 26, 112, 209, 126, 215, 208, 183, 132, 43, 88, 57, 150, 124, 197, 117, 83, 23, 172, 241, 67, 82, 6, 216, 23, 149, 56, 34, 2, 169, 52, 125, 106, 186, 217, 223, 205, 254, 56, 181, 9, 221, 134, 45, 245, 226, 246, 46, 33, 245, 100, 121, 94, 128, 142, 34, 94, 67, 209, 124, 122, 4, 243, 39, 169, 145, 31, 53, 8, 228, 137, 241, 3, 14, 43, 199, 223, 204, 243, 114, 205, 246, 41, 117, 160, 105, 6, 192, 223, 141, 253, 189, 215, 110, 206, 245, 46, 19, 180, 22, 159, 4, 241, 88, 75, 135, 228, 69, 1, 104, 231, 25, 171, 131, 136, 245, 171, 23, 246, 56, 8, 122, 47, 109, 229, 90, 195, 19, 96, 203, 190, 68, 236, 29, 18, 139, 250, 27, 87, 5, 179, 241, 183, 94, 148, 162, 4, 90, 151, 218, 81, 186, 43, 8, 138, 150, 222, 199, 132, 84, 55, 115, 228, 139, 254, 221, 72, 152, 114, 239, 143, 159, 69, 53, 202, 201, 54, 209, 161, 76, 55, 209, 180, 95, 170, 133, 237, 38, 119, 176, 137, 0, 131, 45, 220, 168, 128, 76, 85, 47, 240, 154, 131, 30, 33, 86, 119, 89, 135, 255, 139, 7, 75, 22, 228, 192, 99, 248, 110, 129, 99, 243, 234, 126, 76, 27, 168, 102, 217, 254, 147, 56, 177, 129, 81, 94, 43, 105, 213, 43, 129, 18, 192, 16, 61, 26, 134, 128, 215, 36, 246, 63, 118, 114, 130, 73, 249, 74, 82, 109, 199, 83, 234, 162, 25, 55, 160, 37, 89, 38, 35, 122, 222, 51, 189, 52, 59, 141, 113, 182, 200, 242, 227, 49, 58, 124, 84, 27, 130, 212, 244, 101, 95, 65, 120, 47, 17, 23, 238, 58, 161, 221, 140, 46, 141, 227, 219, 122, 8, 115, 83, 92, 120, 149, 94, 81, 103, 230, 247, 49, 150, 200, 77, 229, 26, 79, 37, 170, 42, 136, 177, 253, 63, 29, 133, 100, 251, 10, 189, 68, 156, 95, 34, 49, 102, 252, 188, 180, 186, 148, 33, 58, 185, 116, 245, 228, 79, 86, 20, 50, 101, 65, 33, 94, 165, 12, 107, 234, 127, 23, 179, 15, 94, 76, 75, 103, 130, 111, 174, 223, 53, 66, 54, 106, 68, 134, 211, 108, 46, 129, 3, 139, 19, 192, 137, 39, 153, 37, 147, 14, 89, 43, 97, 17, 226, 81, 95, 82, 136, 160, 56, 140, 96, 74, 86, 152, 150, 217, 189, 50, 142, 175, 0, 117, 245, 55, 24, 99, 3, 111, 189, 199, 226, 202, 50, 222, 49, 57, 152, 207, 95, 9, 126, 181, 49, 123, 180, 242, 150, 167, 51, 217, 116, 253, 65, 132, 20, 15, 70, 83, 224, 157, 147, 178, 231, 56, 30, 174, 45, 81, 222, 94, 41, 180, 83, 64, 212, 179, 2, 232, 227, 167, 11, 204, 21, 206, 145, 50, 136, 125, 160, 237, 237, 178, 188, 125, 147, 33, 234, 219, 214, 13, 30, 109, 49, 194, 15, 127, 117, 120, 5, 179, 75, 14, 198, 134, 86, 166, 53, 191, 104, 172, 54, 66, 160, 0, 17, 201, 140, 159, 167, 14, 110, 164, 100, 46, 23, 111, 48, 208, 255, 84, 124, 13, 118, 4, 220, 94, 13, 27, 145, 70, 106, 75, 247, 176, 244, 246, 31, 249, 12, 131, 213, 93, 148, 91, 99, 29, 114, 99, 78, 140, 1, 68, 101, 158, 36, 138, 94, 51, 11, 128, 115, 233, 115, 52, 254, 160, 71, 112, 7, 178, 67, 158, 98, 165, 225, 239, 187, 150, 34, 98, 203, 73, 0, 193, 69, 236, 147, 145, 27, 182, 208, 195, 148, 227, 125, 60, 114, 15, 34, 12, 163, 119, 135, 214, 46, 199, 76, 73, 35, 19, 157, 87, 60, 38, 254, 243, 71, 124, 2, 37, 152, 125, 241, 149, 194, 150, 152, 165, 196, 175, 22, 71, 138, 83, 231, 153, 96, 57, 180, 134, 129, 135, 253, 181, 107, 157, 32, 119, 4, 180, 139, 8, 148, 186, 36, 188, 101, 27, 205, 120, 233, 127, 112, 111, 63, 199, 160, 115, 75, 28, 54, 105, 79, 101, 97, 10, 129, 190, 195, 123, 194, 237, 88, 97, 218, 38, 188, 1, 247, 36, 46, 83, 98, 132, 164, 62, 194, 125, 255, 142, 26, 135, 237, 11, 109, 205, 225, 149, 138, 231, 223, 51, 196, 166, 9, 28, 64, 45, 25, 202, 108, 72, 143, 229, 226, 252, 25, 100, 117, 240, 240, 111, 180, 114, 23, 109, 217, 0, 72, 233, 35, 212, 17, 157, 51, 133, 66, 235, 219, 85, 59, 1, 6, 122, 237, 234, 14, 215, 134, 61, 152, 123, 34, 179, 27, 251, 224, 212, 150, 73, 144, 128, 23, 32, 189, 11, 55, 77, 11, 244, 30, 125, 169, 187, 147, 168, 119, 208, 61, 3, 171, 82, 151, 7, 57, 149, 250, 13, 203, 42, 210, 128, 99, 106, 211, 219, 109, 153, 136, 24, 150, 214, 233, 252, 80, 177, 41, 134, 102, 74, 145, 158, 24, 171, 127, 83, 244, 166, 244, 35, 101, 16, 19, 203, 247, 52, 157, 38, 165, 17, 165, 116, 179, 48, 88, 60, 154, 160, 100, 86, 172, 67, 71, 137, 183, 87, 93, 193, 203, 151, 176, 51, 82, 106, 43, 115, 64, 100, 247, 24, 215, 97, 12, 84, 81, 66, 243, 206, 213, 79, 6, 86, 60, 242, 126, 152, 25, 31, 70, 0, 30, 31, 73, 25, 49, 60, 175, 148, 173, 61, 52, 134, 46, 239, 83, 197, 135, 250, 173, 124, 19, 99, 143, 255, 168, 90, 90, 60, 206, 195, 229, 169, 50, 219, 229, 237, 94, 217, 54, 243, 216, 113, 155, 132, 158, 107, 123, 128, 238, 87, 153, 79, 57, 88, 218, 122, 210, 207, 80, 69, 224, 204, 174, 234, 200, 187, 241, 218, 44, 16, 170, 211, 167, 117, 12, 196, 214, 132, 26, 190, 116, 135, 76, 67, 125, 53, 73, 78, 33, 210, 234, 68, 147, 115, 185, 25, 2, 79, 203, 84, 73, 223, 49, 154, 246, 173, 104, 122, 183, 78, 70, 142, 27, 129, 233, 50, 49, 93, 74, 251, 68, 58, 233, 178, 94, 54, 93, 146, 39, 4, 164, 63, 210, 34, 72, 73, 76, 55, 10, 119, 235, 236, 160, 165, 247, 131, 41, 5, 196, 84, 150, 82, 147, 235, 146, 212, 176, 238, 212, 181, 239, 49, 153, 51, 181, 116, 28, 182, 71, 90, 0, 248, 33, 135, 189, 138, 244, 120, 118, 218, 210, 88, 71, 199, 234, 235, 255, 217, 5, 152, 185, 87, 142, 77, 253, 240, 207, 221, 80, 166, 88, 22, 55, 100, 23, 3, 247, 177, 68, 233, 164, 77, 193, 228, 81, 244, 137, 45, 62, 44, 249, 25, 50, 118, 44, 236, 20, 88, 71, 64, 6, 152, 150, 153, 112, 255, 187, 5, 192, 233, 162, 201, 50, 95, 4, 243, 137, 101, 143, 223, 211, 83, 32, 122, 16, 55, 89, 7, 13, 86, 189, 0, 134, 237, 65, 147, 154, 167, 180, 164, 178, 228, 87, 223, 40, 84, 206, 234, 37, 177, 174, 71, 106, 226, 199, 29, 228, 120, 72, 49, 89, 41, 188, 114, 125, 178, 181, 229, 164, 198, 32, 215, 88, 115, 191, 131, 160, 24, 101, 169, 154, 200, 65, 85, 52, 12, 95, 182, 76, 26, 158, 197, 121, 43, 145, 3, 247, 166, 224, 231, 142, 100, 238, 1, 169, 240, 193, 83, 28, 240, 27, 235, 102, 172, 203, 161, 250, 10, 74, 137, 10, 24, 200, 222, 129, 22, 156, 83, 166, 92, 138, 213, 142, 78, 247, 38, 229, 169, 34, 59, 227, 37, 250, 14, 146, 165, 142, 242, 161, 160, 116, 46, 111, 133, 125, 43, 46, 184, 183, 106, 233, 122, 167, 138, 206, 103, 15, 119, 134, 0, 224, 179, 9, 179, 81, 181, 210, 164, 236, 44, 234, 17, 151, 181, 238, 97, 71, 31, 83, 204, 35, 83, 129, 179, 250, 222, 140, 80, 8, 244, 89, 210, 79, 39, 74, 206, 66, 201, 160, 161, 247, 115, 81, 153, 130, 237, 80, 7, 120, 73, 94, 239, 99, 237, 120, 5, 48, 94, 87, 235, 158, 177, 230, 47, 79, 116, 140, 23, 165, 36, 250, 58, 18, 138, 70, 157, 126, 43, 135, 33, 147, 52, 88, 154, 181, 234, 216, 248, 153, 24, 132, 164, 90, 129, 76, 111, 24, 120, 93, 36, 223, 47, 55, 207, 228, 161, 236, 60, 74, 40, 105, 190, 250, 50, 42, 105, 114, 56, 149, 205, 154, 110, 114, 21, 137, 27, 123, 250, 130, 122, 159, 41, 233, 112, 109, 93, 242, 21, 109, 242, 30, 166, 41, 178, 65, 160, 33, 125, 137, 90, 168, 218, 241, 105, 227, 147, 129, 46, 132, 143, 46, 242, 144, 67, 52, 232, 43, 43, 187, 77, 17, 127, 154, 105, 220, 225, 168, 74, 151, 5, 223, 22, 16, 99, 172, 120, 221, 189, 75, 151, 4, 163, 189, 0, 174, 150, 214, 211, 207, 113, 188, 56, 20, 218, 234, 81, 138, 36, 36, 251, 58, 180, 81, 156, 51, 111, 61, 161, 35, 235, 106, 230, 166, 91, 125, 244, 27, 52, 55, 113, 43, 227, 121, 71, 12, 15, 191, 7, 226, 37, 54, 196, 249, 59, 205, 207, 234, 191, 251, 143, 86, 186, 200, 154, 175, 230, 107, 39, 235, 7, 112, 15, 3, 162, 53, 254, 49, 50, 75, 242, 15, 140, 35, 82, 18, 16, 58, 44, 43, 35, 117, 146, 137, 17, 181, 34, 209, 206, 190, 108, 77, 139, 56, 121, 135, 62, 179, 250, 163, 142, 34, 245, 193, 223, 175, 186, 63, 148, 177, 12, 213, 3, 31, 74, 74, 251, 244, 159, 243, 41, 155, 24, 54, 121, 103, 18, 13, 109, 17, 71, 101, 175, 40, 70, 17, 5, 141, 3, 49, 190, 105, 126, 43, 127, 98, 87, 178, 11, 189, 91, 236, 34, 9, 226, 92, 26, 5, 255, 177, 176, 140, 92, 99, 23, 219, 232, 105, 125, 170, 157, 161, 154, 235, 203, 71, 103, 139, 166, 224, 147, 176, 96, 251, 184, 153, 228, 51, 61, 87, 231, 220, 96, 111, 231, 125, 223, 214, 221, 54, 216, 213, 100, 134, 216, 35, 174, 107, 72, 191, 83, 232, 55, 19, 95, 151, 144, 247, 222, 32, 2, 32, 102, 255, 147, 248, 245, 192, 162, 88, 24, 255, 191, 73, 198, 144, 95, 27, 146, 232, 64, 131, 197, 30, 71, 15, 193, 42, 108, 38, 144, 112, 250, 162, 146, 31, 152, 135, 211, 15, 194, 39, 99, 35, 177, 165, 21, 139, 252, 238, 241, 50, 239, 52, 103, 169, 149, 143, 34, 116, 58, 55, 254, 172, 173, 215, 125, 206, 15, 208, 179, 112, 5, 11, 121, 128, 7, 121, 87, 185, 4, 44, 235, 97, 55, 154, 212, 236, 168, 51, 1, 91, 64, 86, 100, 165, 11, 15, 52, 82, 132, 171, 232, 145, 19, 217, 94, 216, 168, 150, 52, 194, 9, 246, 128, 10, 87, 144, 51, 218, 153, 6, 31, 185, 41, 230, 196, 68, 39, 92, 86, 183, 56, 34, 48, 50, 75, 94, 166, 214, 128, 219, 194, 164, 238, 122, 83, 54, 93, 150, 180, 234, 208, 194, 59, 145, 246, 70, 150, 251, 224, 250, 226, 181, 191, 128, 230, 249, 235, 203, 112, 226, 167, 217, 16, 88, 41, 30, 229, 142, 222, 222, 211, 71, 206, 191, 36, 118, 123, 230, 244, 45, 158, 245, 18, 140, 183, 63, 176, 86, 201, 150, 129, 149, 170, 193, 102, 96, 241, 28, 2, 151, 190, 120, 83, 73, 75, 81, 74, 94, 189, 166, 214, 148, 152, 221, 24, 183, 161, 252, 1, 73, 179, 82, 63, 223, 3, 44, 100, 10, 151, 238, 124, 168, 63, 196, 184, 68, 52, 142, 182, 122, 102, 120, 201, 9, 162, 202, 239, 202, 173, 185, 123, 73, 167, 169, 10, 17, 239, 142, 33, 81, 209, 126, 69, 103, 0, 246, 112, 5, 32, 114, 98, 129, 160, 56, 65, 66, 66, 69, 94, 198, 33, 180, 240, 76, 124, 82, 142, 157, 47, 122, 218, 172, 219, 235, 21, 70, 29, 249, 218, 92, 99, 186, 54, 146, 21, 152, 230, 149, 11, 34, 180, 45, 119, 203, 53, 165, 130, 142, 14, 171, 182, 64, 153, 35, 178, 138, 80, 9, 8, 198, 170, 247, 140, 182, 130, 173, 204, 143, 127, 43, 177, 212, 154, 187, 205, 167, 76, 27, 6, 160, 111, 167, 92, 231, 218, 77, 131, 53, 93, 248, 182, 66, 124, 42, 215, 242, 210, 189, 39, 125, 173, 36, 29, 20, 185, 218, 196, 46, 165, 128, 86, 42, 98, 85, 254, 154, 44, 100, 2, 25, 127, 36, 157, 43, 237, 225, 199, 146, 44, 186, 82, 243, 128, 63, 160, 10, 238, 94, 228, 224, 95, 164, 183, 232, 84, 186, 132, 145, 165, 64, 152, 183, 201, 251, 172, 20, 53, 151, 95, 161, 75, 40, 119, 56, 109, 172, 129, 26, 220, 24, 76, 23, 252, 115, 191, 21, 184, 41, 222, 235, 206, 170, 211, 230, 159, 94, 52, 215, 176, 10, 228, 190, 160, 247, 47, 157, 145, 32, 137, 72, 214, 237, 191, 15, 187, 171, 39, 205, 48, 197, 101, 161, 138, 232, 87, 2, 86, 55, 153, 202, 138, 72, 234, 11, 63, 129, 142, 230, 151, 174, 22, 170, 141, 123, 208, 153, 237, 228, 143, 255, 33, 73, 202, 101, 126, 4, 117, 182, 161, 254, 80, 63, 51, 46, 207, 174, 144, 244, 193, 73, 12, 211, 248, 131, 39, 241, 63, 16, 141, 40, 127, 188, 42, 97, 247, 139, 63, 240, 61, 146, 78, 246, 56, 53, 65, 249, 108, 22, 84, 102, 132, 32, 133, 201, 142, 175, 1, 4, 248, 160, 79, 248, 115, 71, 80, 35, 175, 57, 193, 255, 27, 122, 45, 249, 120, 249, 40, 29, 70, 41, 246, 39, 203, 26, 25, 212, 190, 88, 171, 75, 153, 125, 75, 222, 185, 122, 17, 224, 120, 132, 166, 22, 2, 24, 58, 45, 120, 227, 223, 161, 92, 193, 60, 56, 236, 91, 252, 67, 65, 252, 75, 148, 220, 168, 159, 143, 177, 227, 36, 208, 96, 9, 120, 195, 69, 219, 96, 132, 235, 239, 242, 239, 173, 239, 236, 58, 245, 94, 86, 77, 206, 178, 136, 203, 59, 149, 140, 158, 104, 149, 194, 78, 170, 55, 217, 164, 13, 194, 217, 243, 237, 22, 88, 88, 177, 135, 115, 117, 135, 71, 50, 114, 4, 54, 10, 91, 31, 132, 163, 2, 36, 2, 27, 22, 56, 232, 216, 34, 141, 8, 130, 105, 154, 9, 12, 250, 225, 100, 93, 109, 208, 145, 77, 151, 99, 39, 73, 186, 232, 172, 111, 26, 39, 225, 164, 156, 41, 124, 120, 212, 242, 51, 193, 226, 50, 172, 150, 56, 62, 118, 1, 84, 52, 253, 202, 180, 48, 30, 179, 29, 82, 185, 50, 69, 17, 189, 54, 169, 210, 87, 63, 238, 229, 7, 212, 71, 251, 34, 91, 192, 229, 198, 136, 160, 221, 149, 172, 165, 149, 107, 114, 153, 85, 170, 206, 43, 5, 233, 197, 95, 238, 212, 189, 31, 254, 215, 146, 235, 189, 162, 11, 0, 185, 186, 72, 10, 35, 86, 217, 76, 235, 110, 86, 57, 87, 20, 223, 96, 163, 208, 228, 45, 82, 33, 69, 219, 135, 59, 235, 152, 230, 138, 15, 117, 108, 88, 83, 194, 142, 238, 45, 93, 159, 104, 106, 17, 77, 238, 68, 58, 240, 86, 59, 144, 221, 70, 255, 221, 219, 85, 42, 127, 231, 141, 169, 114, 166, 2, 201, 163, 237, 34, 78, 26, 5, 202, 11, 137, 188, 207, 192, 86, 120, 155, 2, 205, 189, 164, 178, 176, 32, 127, 165, 209, 3, 11, 140, 174, 107, 163, 51, 100, 81, 44, 247, 103, 140, 229, 223, 118, 63, 202, 200, 1, 135, 156, 143, 48, 148, 152, 128, 81, 208, 127, 25, 102, 120, 106, 96, 142, 22, 153, 129, 234, 215, 92, 128, 64, 121, 172, 248, 21, 30, 38, 117, 21, 224, 44, 51, 81, 188, 165, 64, 230, 64, 158, 172, 255, 16, 26, 251, 70, 154, 161, 41, 110, 193, 75, 12, 232, 46, 23, 10, 56, 170, 237, 227, 119, 22, 134, 205, 212, 2, 167, 39, 27, 141, 251, 250, 45, 245, 154, 26, 29, 166, 157, 180, 153, 243, 55, 50, 59, 87, 144, 164, 140, 83, 169, 47, 46, 233, 200, 234, 94, 16, 156, 169, 140, 240, 56, 11, 168, 129, 48, 236, 54, 46, 152, 127, 30, 100, 76, 38, 160, 130, 218, 154, 131, 61, 105, 7, 113, 46, 23, 224, 187, 247, 103, 128, 254, 112, 207, 252, 159, 38, 13, 38, 26, 28, 83, 156, 32, 94, 193, 250, 198, 220, 13, 185, 36, 1, 161, 219, 136, 150, 166, 219, 214, 121, 106, 95, 5, 2, 225, 21, 97, 241, 21, 43, 247, 128, 59, 244, 172, 40, 182, 69, 207, 238, 1, 183, 176, 84, 179, 250, 28, 18, 191, 250, 166, 112, 34, 56, 188, 37, 122, 120, 170, 107, 130, 102, 30, 165, 159, 236, 54, 88, 47, 217, 233, 215, 215, 77, 151, 62, 19, 138, 128, 89, 103, 50, 53, 123, 161, 246, 65, 170, 232, 187, 100, 151, 173, 157, 41, 124, 54, 213, 176, 95, 251, 176, 219, 212, 219, 87, 137, 221, 158, 116, 201, 11, 231, 13, 115, 217, 176, 171, 97, 33, 205, 42, 86, 197, 137, 143, 255, 91, 163, 247, 65, 109, 0, 29, 30, 67, 225, 251, 253, 53, 190, 105, 129, 235, 29, 42, 251, 146, 247, 196, 232, 128, 24, 229, 62, 67, 129, 20, 31, 57, 207, 127, 2, 15, 98, 97, 7, 216, 66, 40, 77, 169, 153, 109, 197, 142, 185, 250, 8, 200, 233, 200, 75, 250, 201, 133, 182, 69, 126, 151, 192, 107, 100, 105, 202, 145, 164, 245, 186, 5, 96, 4, 142, 101, 237, 123, 144, 68, 245, 28, 229, 255, 211, 113, 255, 40, 126, 11, 153, 206, 138, 3, 79, 199, 172, 3, 10, 150, 144, 17, 154, 242, 4, 107, 153, 113, 77, 159, 229, 13, 92, 251, 41, 71, 212, 254, 151, 113, 19, 93, 72, 57, 195, 229, 169, 88, 232, 57, 79, 216, 97, 10, 152, 186, 36, 146, 186, 154, 94, 245, 52, 237, 41, 165, 185, 128, 201, 223, 164, 79, 54, 127, 245, 53, 252, 94, 196, 187, 229, 117, 211, 38, 231, 227, 208, 169, 246, 18, 145, 71, 98, 201, 134, 51, 247, 122, 243, 160, 205, 22, 137, 123, 68, 46, 214, 164, 232, 213, 240, 195, 223, 134, 213, 190, 132, 128, 141, 20, 236, 57, 173, 58, 13, 196, 37, 198, 86, 175, 209, 101, 61, 246, 46, 218, 101, 173, 189, 48, 102, 56, 109, 117, 58, 32, 152, 162, 44, 187, 65, 129, 42, 61, 175, 199, 39, 213, 140, 85, 102, 107, 223, 243, 238, 34, 169, 95, 251, 94, 143, 243, 168, 242, 220, 82, 84, 157, 177, 210, 226, 153, 208, 129, 13, 176, 152, 119, 135, 245, 227, 67, 42, 207, 227, 141, 82, 60, 79, 143, 17, 63, 99, 44, 181, 58, 8, 5, 15, 228, 247, 139, 20, 144, 43, 154, 203, 226, 33, 20, 208, 162, 39, 241, 89, 73, 140, 76, 233, 216, 31, 41, 101, 203, 211, 1, 120, 9, 124, 121, 113, 47, 253, 4, 22, 65, 95, 223, 37, 95, 24, 87, 59, 142, 58, 55, 201, 239, 76, 181, 39, 195, 92, 59, 119, 168, 139, 245, 73, 28, 183, 210, 75, 185, 149, 70, 185, 40, 131, 109, 174, 47, 47, 22, 13, 197, 229, 178, 81, 75, 111, 124, 102, 215, 131, 140, 120, 159, 52, 76, 153, 68, 103, 19, 81, 231, 65, 171, 128, 65, 191, 217, 99, 122, 16, 229, 130, 68, 231, 131, 149, 227, 133, 200, 46, 130, 44, 181, 234, 55, 44, 207, 248, 132, 200, 177, 82, 203, 148, 79, 209, 42, 64, 8, 233, 96, 40, 232, 222, 58, 78, 117, 213, 151, 81, 205, 252, 239, 124, 230, 79, 105, 249, 153, 187, 58, 62, 9, 244, 78, 71, 162, 80, 204, 14, 1, 221, 170, 195, 170, 69, 100, 178, 124, 226, 24, 219, 127, 77, 232, 80, 160, 63, 252, 205, 220, 245, 49, 231, 177, 170, 110, 33, 94, 137, 148, 168, 120, 103, 170, 201, 2, 254, 65, 102, 169, 46, 132, 111, 109, 65, 88, 13, 102, 80, 146, 215, 214, 161, 51, 158, 121, 54, 111, 221, 58, 232, 35, 165, 194, 248, 46, 206, 139, 243, 101, 180, 41, 169, 248, 75, 181, 253, 0, 205, 214, 234, 241, 197, 44, 156, 249, 164, 2, 248, 45, 21, 2, 161, 150, 110, 154, 74, 237, 253, 39, 188, 120, 76, 193, 138, 121, 76, 105, 130, 141, 139, 222, 32, 64, 136, 19, 214, 92, 116, 113, 148, 113, 162, 217, 27, 50, 97, 169, 16, 50, 198, 226, 156, 155, 162, 110, 67, 36, 128, 204, 8, 152, 128, 72, 246, 58, 189, 45, 133, 150, 214, 150, 6, 124, 16, 49, 17, 35, 181, 21, 61, 23, 60, 81, 71, 77, 44, 108, 49, 222, 223, 107, 110, 226, 207, 238, 108, 12, 104, 227, 252, 63, 24, 214, 198, 13, 31, 210, 85, 156, 80, 247, 4, 28, 217, 43, 224, 101, 8, 228, 31, 0, 130, 95, 47, 52, 225, 87, 96, 89, 118, 37, 144, 136, 55, 247, 217, 114, 243, 46, 120, 135, 223, 179, 24, 58, 99, 14, 191, 238, 137, 206, 27, 164, 126, 72, 35, 206, 63, 213, 181, 252, 116, 40, 194, 227, 141, 233, 129, 57, 69, 33, 55, 91, 139, 160, 219, 62, 244, 36, 235, 49, 108, 98, 229, 195, 28, 88, 153, 206, 9, 201, 25, 132, 215, 155, 221, 67, 226, 74, 187, 32, 105, 101, 32, 221, 31, 102, 46, 193, 222, 221, 28, 209, 38, 85, 82, 56, 178, 101, 236, 44, 177, 105, 130, 12, 251, 149, 155, 123, 0, 243, 241, 241, 120, 19, 242, 47, 73, 109, 105, 254, 9, 139, 251, 63, 84, 62, 65, 40, 16, 133, 163, 216, 238, 18, 237, 0, 9, 227, 133, 135, 28, 120, 52, 234, 151, 21, 32, 79, 120, 8, 143, 108, 178, 27, 174, 114, 173, 15, 137, 15, 179, 229, 158, 7, 169, 223, 146, 217, 154, 79, 183, 27, 85, 98, 74, 210, 9, 106, 190, 59, 10, 147, 159, 128, 70, 61, 148, 198, 27, 209, 52, 158, 12, 216, 148, 244, 222, 9, 148, 219, 185, 250, 72, 203, 242, 143, 6, 170, 25, 255, 76, 226, 195, 62, 254, 55, 185, 251, 72, 225, 110, 91, 109, 86, 91, 131, 174, 237, 210, 136, 180, 121, 61, 170, 234, 223, 55, 186, 45, 156, 75, 49, 92, 25, 170, 34, 184, 59, 109, 243, 15, 215, 144, 244, 20, 0, 254, 117, 18, 25, 14, 200, 191, 252, 171, 224, 0, 169, 226, 132, 2, 199, 166, 255, 59, 53, 179, 58, 50, 234, 197, 57, 171, 6, 222, 163, 213, 94, 252, 148, 127, 139, 213, 180, 108, 9, 226, 92, 174, 17, 178, 39, 164, 245, 231, 116, 228, 1, 148, 16, 215, 150, 7, 121, 193, 245, 189, 29, 28, 20, 254, 93, 107, 54, 105, 174, 225, 166, 143, 242, 130, 136, 3, 13, 191, 185, 172, 163, 125, 61, 253, 71, 251, 161, 16, 215, 186, 201, 213, 253, 12, 233, 212, 232, 94, 177, 218, 85, 211, 226, 60, 96, 42, 43, 236, 68, 8, 152, 94, 70, 181, 17, 41, 15, 118, 195, 178, 13, 84, 249, 132, 111, 73, 196, 90, 61, 218, 79, 139, 200, 125, 2, 42, 174, 188, 52, 108, 112, 52, 4, 166, 239, 187, 235, 123, 15, 231, 70, 160, 116, 192, 171, 99, 34, 107, 31, 228, 77, 199, 61, 59, 141, 137, 195, 207, 17, 1, 255, 6, 32, 52, 198, 173, 198, 211, 197, 56, 223, 95, 144, 244, 74, 65, 162, 37, 218, 163, 58, 156, 132, 6, 183, 200, 50, 110, 19, 214, 248, 131, 92, 254, 215, 183, 159, 101, 125, 231, 161, 90, 194, 65, 156, 162, 169, 28, 67, 62, 254, 177, 185, 205, 38, 41, 115, 238, 241, 143, 141, 90, 40, 154, 153, 208, 153, 193, 127, 182, 41, 230, 248, 183, 1, 206, 116, 143, 150, 92, 242, 251, 115, 214, 18, 195, 251, 170, 68, 190, 126, 64, 174, 55, 130, 245, 26, 105, 205, 40, 71, 148, 194, 66, 90, 243, 166, 19, 237, 137, 149, 13, 228, 165, 122, 218, 62, 202, 37, 16, 37, 163, 226, 18, 158, 70, 144, 162, 241, 62, 155, 214, 222, 22, 213, 199, 214, 202, 70, 99, 10, 131, 250, 199, 175, 175, 3, 248, 68, 109, 161, 246, 144, 182, 164, 209, 126, 12, 31, 140, 158, 97, 98, 247, 151, 57, 192, 108, 206, 201, 189, 129, 6, 221, 89, 84, 232, 206, 42, 54, 195, 172, 59, 245, 84, 40, 30, 81, 147, 17, 172, 133, 1, 219, 138, 186, 158, 88, 23, 119, 39, 115, 225, 27, 109, 124, 20, 85, 104, 27, 33, 120, 164, 26, 199, 167, 41, 109, 198, 115, 99, 225, 3, 17, 118, 170, 219, 233, 202, 31, 241, 191, 217, 50, 118, 151, 172, 222, 214, 7, 85, 96, 222, 194, 51, 59, 55, 58, 109, 180, 208, 98, 138, 2, 148, 180, 62, 97, 104, 181, 59, 33, 234, 84, 103, 215, 220, 66, 74, 193, 176, 28, 19, 252, 172, 105, 239, 104, 100, 27, 126, 209, 250, 62, 210, 111, 106, 77, 179, 231, 28, 171, 131, 185, 106, 211, 205, 18, 91, 82, 136, 231, 171, 26, 216, 194, 116, 221, 40, 175, 151, 92, 56, 57, 215, 205, 146, 10, 60, 159, 9, 23, 48, 6, 244, 117, 158, 2, 103, 54, 183, 85, 93, 255, 136, 213, 199, 87, 254, 145, 113, 14, 179, 211, 186, 235, 70, 139, 156, 16, 114, 208, 198, 71, 213, 249, 172, 41, 73, 29, 1, 1, 82, 55, 141, 161, 142, 67, 212, 117, 69, 56, 75, 53, 153, 236, 165, 213, 59, 36, 223, 17, 200, 39, 151, 230, 123, 236, 233, 175, 89, 171, 29, 126, 200, 204, 166, 44, 209, 21, 26, 205, 126, 160, 224, 219, 145, 96, 227, 65, 7, 245, 76, 92, 87, 32, 67, 133, 72, 232, 15, 54, 148, 9, 34, 246, 79, 194, 12, 133, 236, 144, 163, 37, 5, 199, 199, 11, 127, 126, 85, 91, 102, 208, 248, 220, 102, 50, 130, 136, 29, 236, 69, 45, 146, 97, 199, 195, 54, 246, 82, 6, 45, 203, 67, 100, 111, 15, 51, 54, 191, 12, 167, 201, 53, 47, 225, 14, 100, 233, 172, 16, 5, 155, 125, 204, 17, 147, 180, 241, 106, 249, 178, 184, 36, 236, 205, 145, 234, 101, 236, 81, 63, 136, 187, 159, 131, 156, 168, 56, 246, 76, 32, 17, 207, 249, 175, 163, 93, 78, 36, 27, 173, 144, 252, 114, 213, 15, 227, 234, 234, 71, 146, 148, 102, 18, 193, 227, 205, 112, 250, 193, 220, 168, 120, 119, 190, 42, 124, 47, 125, 219, 42, 34, 40, 95, 195, 28, 159, 222, 65, 143, 29, 97, 209, 68, 60, 86, 157, 206, 68, 103, 248, 145, 209, 14, 210, 112, 170, 227, 164, 23, 153, 167, 151, 164, 50, 253, 160, 108, 68, 185, 247, 221, 149, 165, 144, 123, 7, 95, 85, 121, 32, 77, 215, 137, 121, 158, 85, 24, 2, 165, 116, 18, 140, 243, 116, 165, 114, 203, 253, 240, 93, 156, 157, 107, 255, 154, 169, 110, 140, 14, 225, 50, 96, 95, 35, 45, 98, 71, 192, 200, 122, 65, 228, 117, 160, 65, 181, 2, 62, 17, 48, 59, 163, 186, 121, 46, 104, 200, 205, 8, 43, 134, 175, 155, 181, 143, 14, 228, 235, 185, 120, 120, 59, 156, 232, 86, 187, 61, 234, 169, 47, 246, 251, 34, 71, 189, 70, 141, 60, 44, 15, 209, 28, 37, 198, 210, 252, 199, 157, 39, 77, 91, 203, 248, 97, 61, 200, 119, 47, 119, 208, 134, 24, 249, 136, 6, 107, 177, 189, 13, 233, 127, 23, 4, 252, 193, 41, 254, 26, 150, 168, 81, 255, 99, 158, 250, 108, 93, 58, 159, 197, 152, 225, 224, 34, 36, 187, 160, 101, 92, 197, 50, 111, 39, 59, 161, 124, 81, 63, 79, 172, 103, 71, 169, 231, 156, 93, 43, 120, 197, 90, 110, 229, 141, 183, 110, 147, 126, 31, 20, 174, 227, 8, 3, 201, 51, 8, 25, 147, 176, 246, 100, 126, 182, 92, 91, 234, 95, 7, 174, 8, 74, 223, 66, 106, 57, 193, 212, 247, 227, 172, 170, 229, 144, 92, 60, 149, 176, 185, 92, 154, 71, 179, 68, 146, 117, 80, 91, 46, 60, 194, 205, 81, 85, 246, 237, 227, 79, 51, 247, 57, 167, 37, 75, 194, 57, 224, 142, 3, 237, 113, 19, 120, 178, 168, 129, 86, 35, 159, 66, 116, 36, 241, 17, 122, 157, 218, 122, 33, 245, 25, 227, 112, 135, 62, 227, 223, 154, 195, 252, 220, 129, 206, 65, 29, 112, 205, 22, 132, 65, 222, 109, 91, 45, 112, 133, 0, 38, 37, 230, 95, 96, 29, 113, 8, 168, 190, 233, 97, 168, 162, 169, 206, 237, 102, 26, 172, 238, 90, 138, 82, 119, 225, 164, 167, 156, 206, 140, 2, 103, 94, 108, 8, 65, 173, 52, 62, 251, 52, 31, 39, 175, 45, 197, 87, 12, 190, 51, 123, 105, 108, 5, 199, 34, 100, 17, 244, 233, 237, 184, 198, 19, 244, 78, 33, 205, 219, 77, 207, 64, 252, 45, 20, 232, 196, 68, 112, 152, 118, 9, 221, 33, 107, 182, 159, 157, 95, 28, 168, 198, 100, 45, 230, 195, 204, 7, 161, 80, 225, 228, 68, 108, 121, 107, 165, 251, 68, 47, 216, 103, 84, 27, 71, 213, 63, 183, 57, 3, 186, 144, 161, 235, 210, 91, 89, 140, 72, 14, 81, 187, 39, 77, 99, 133, 45, 76, 221, 239, 76, 143, 202, 140, 159, 152, 230, 154, 217, 65, 191, 82, 150, 59, 200, 237, 194, 159, 154, 52, 254, 32, 93, 113, 27, 226, 149, 48, 117, 40, 198, 164, 144, 132, 217, 184, 23, 150, 196, 11, 28, 239, 212, 70, 79, 41, 20, 83, 64, 162, 58, 134, 245, 120, 67, 201, 32, 31, 163, 100, 246, 203, 139, 157, 21, 90, 198, 39, 181, 95, 168, 13, 35, 158, 141, 55, 173, 17, 69, 106, 143, 81, 205, 66, 88, 189, 68, 40, 166, 110, 201, 144, 25, 112, 6, 248, 124, 125, 119, 56, 237, 84, 253, 136, 134, 204, 213, 70, 33, 255, 189, 151, 69, 126, 215, 42, 255, 235, 82, 110, 113, 249, 28, 71, 255, 246, 197, 90, 219, 57, 20, 98, 116, 108, 222, 36, 103, 137, 182, 240, 62, 138, 11, 252, 71, 196, 173, 10, 1, 243, 15, 89, 196, 4, 154, 152, 87, 137, 118, 182, 128, 88, 126, 58, 125, 151, 243, 114, 71, 251, 44, 0, 233, 93, 122, 190, 110, 143, 102, 8, 210, 253, 148, 245, 165, 115, 15, 245, 184, 196, 26, 131, 165, 116, 68, 76, 89, 134, 222, 163, 207, 167, 55, 182, 217, 174, 214, 25, 202, 159, 252, 247, 243, 120, 98, 44, 0, 78, 35, 57, 121, 139, 47, 236, 4, 152, 4, 178, 70, 186, 174, 1, 178, 130, 190, 145, 23, 186, 123, 229, 249, 167, 221, 159, 162, 12, 4, 49, 106, 33, 9, 123, 222, 8, 160, 213, 87, 105, 154, 87, 122, 153, 42, 20, 190, 69, 7, 120, 186, 46, 75, 52, 148, 14, 235, 86, 106, 209, 25, 92, 129, 123, 170, 54, 107, 5, 173, 141, 78, 141, 243, 12, 96, 165, 163, 59, 105, 171, 118, 209, 161, 50, 36, 42, 210, 203, 139, 84, 92, 254, 108, 255, 243, 197, 210, 215, 251, 246, 254, 91, 102, 96, 44, 66, 28, 22, 184, 97, 229, 171, 122, 1, 217, 108, 215, 125, 218, 97, 178, 170, 178, 89, 64, 47, 89, 127, 4, 171, 249, 81, 199, 40, 232, 129, 15, 250, 155, 74, 90, 183, 70, 218, 183, 16, 142, 84, 10, 3, 80, 59, 221, 50, 86, 92, 210, 159, 193, 234, 105, 118, 228, 119, 20, 221, 44, 95, 231, 138, 1, 77, 194, 22, 197, 36, 82, 115, 166, 255, 243, 239, 202, 79, 129, 233, 150, 189, 143, 11, 53, 180, 79, 183, 186, 192, 51, 112, 119, 37, 26, 55, 29, 190, 110, 22, 52, 185, 207, 255, 188, 122, 2, 178, 31, 102, 170, 1, 37, 248, 105, 118, 81, 236, 59, 246, 115, 140, 115, 212, 160, 252, 180, 71, 97, 220, 188, 179, 150, 185, 166, 7, 125, 133, 102, 112, 2, 197, 66, 55, 186, 30, 65, 80, 212, 13, 10, 9, 2, 57, 99, 214, 66, 159, 119, 255, 203, 170, 112, 161, 28, 169, 46, 220, 236, 110, 137, 151, 110, 5, 122, 3, 29, 167, 236, 3, 181, 232, 252, 122, 172, 222, 208, 122, 199, 34, 105, 38, 86, 207, 89, 241, 210, 29, 19, 111, 54, 113, 172, 99, 128, 240, 247, 231, 244, 245, 135, 232, 90, 197, 211, 112, 63, 64, 49, 131, 148, 82, 11, 170, 247, 245, 190, 197, 118, 127, 217, 204, 208, 231, 254, 37, 148, 143, 83, 252, 67, 47, 146, 53, 39, 96, 76, 20, 98, 225, 16, 166, 48, 86, 60, 9, 221, 166, 127, 142, 24, 18, 85, 123, 188, 214, 198, 149, 53, 4, 189, 52, 67, 164, 40, 236, 93, 159, 54, 75, 212, 64, 107, 160, 184, 47, 177, 134, 233, 157, 236, 225, 146, 214, 74, 248, 228, 160, 163, 37, 237, 55, 27, 54, 206, 173, 112, 179, 115, 154, 182, 142, 211, 235, 215, 163, 84, 179, 41, 123, 51, 196, 144, 126, 69, 195, 210, 202, 231, 221, 75, 199, 235, 129, 73, 153, 63, 236, 193, 164, 242, 20, 121, 155, 126, 224, 82, 142, 106, 158, 144, 143, 254, 27, 150, 251, 97, 17, 76, 169, 21, 0, 181, 78, 217, 23, 250, 152, 139, 47, 81, 193, 98, 107, 20, 212, 138, 64, 218, 52, 163, 108, 179, 234, 47, 253, 58, 231, 171, 228, 172, 97, 190, 48, 146, 23, 132, 233, 144, 20, 113, 193, 138, 202, 107, 18, 101, 234, 82, 28, 24, 168, 171, 160, 15, 58, 110, 46, 155, 62, 242, 21, 45, 245, 206, 147, 240, 172, 103, 5, 146, 252, 189, 152, 106, 36, 171, 160, 108, 238, 236, 7, 135, 214, 195, 42, 191, 229, 211, 113, 125, 124, 172, 99, 160, 110, 206, 14, 234, 163, 141, 18, 117, 97, 46, 249, 234, 137, 190, 171, 29, 239, 68, 53, 59, 166, 243, 218, 185, 80, 232, 24, 73, 128, 105, 213, 81, 239, 110, 246, 87, 144, 24, 212, 83, 195, 232, 196, 128, 34, 169, 24, 143, 47, 56, 81, 70, 249, 144, 88, 250, 3, 135, 235, 26, 34, 153, 173, 60, 213, 175, 239, 33, 230, 222, 158, 193, 171, 233, 232, 77, 143, 86, 109, 244, 7, 131, 78, 169, 51, 155, 146, 122, 34, 52, 252, 58, 226, 206, 7, 250, 145, 114, 240, 244, 231, 5, 148, 209, 126, 35, 109, 126, 0, 103, 136, 154, 228, 47, 214, 100, 224, 139, 18, 223, 14, 233, 85, 127, 182, 26, 42, 51, 19, 72, 65, 128, 149, 75, 156, 251, 0, 235, 45, 162, 100, 148, 251, 108, 29, 217, 1, 123, 21, 226, 210, 147, 61, 220, 13, 97, 54, 213, 82, 161, 57, 100, 161, 70, 55, 232, 51, 72, 219, 153, 62, 79, 97, 38, 231, 28, 68, 69, 200, 38, 42, 117, 125, 60, 210, 218, 224, 124, 77, 118, 186, 190, 107, 175, 135, 41, 20, 141, 67, 181, 128, 244, 102, 18, 242, 157, 82, 68, 152, 135, 234, 223, 167, 182, 230, 55, 70, 240, 41, 201, 215, 137, 158, 27, 208, 122, 52, 182, 129, 69, 99, 194, 211, 36, 33, 177, 177, 251, 158, 46, 161, 134, 233, 97, 229, 170, 159, 106, 244, 130, 92, 205, 216, 181, 7, 182, 235, 215, 234, 188, 138, 45, 77, 34, 82, 58, 9, 73, 63, 109, 96, 85, 34, 52, 12, 124, 62, 221, 209, 31, 126, 194, 91, 217, 57, 212, 184, 19, 253, 127, 208, 235, 149, 216, 23, 122, 58, 3, 177, 182, 69, 135, 53, 99, 204, 176, 203, 116, 140, 29, 80, 134, 56, 30, 80, 138, 169, 51, 90, 78, 4, 40, 34, 5, 18, 11, 69, 103, 217, 36, 150, 97, 242, 249, 150, 75, 65, 162, 20, 104, 8, 139, 94, 211, 101, 43, 75, 163, 33, 104, 91, 167, 48, 244, 23, 168, 110, 87, 15, 148, 242, 3, 59, 65, 78, 21, 211, 71, 215, 176, 244, 2, 119, 242, 201, 23, 174, 49, 104, 189, 112, 72, 67, 42, 126, 52, 79, 127, 185, 62, 212, 150, 85, 148, 237, 49, 229, 191, 108, 166, 223, 219, 225, 131, 227, 29, 141, 170, 108, 113, 40, 99, 44, 124, 241, 3, 209, 181, 213, 187, 142, 187, 106, 108, 128, 225, 180, 244, 95, 116, 24, 147, 150, 147, 150, 194, 105, 36, 12, 214, 98, 86, 95, 133, 115, 249, 14, 43, 9, 62, 34, 159, 245, 91, 45, 173, 107, 77, 8, 109, 213, 189, 172, 190, 233, 231, 226, 79, 118, 35, 180, 5, 16, 116, 146, 194, 214, 135, 246, 28, 0, 177, 62, 28, 186, 211, 62, 204, 203, 121, 145, 86, 99, 8, 140, 26, 14, 39, 9, 8, 175, 223, 211, 151, 9, 189, 124, 230, 240, 207, 188, 129, 106, 151, 9, 14, 71, 194, 21, 30, 212, 75, 166, 183, 234, 87, 242, 144, 192, 55, 235, 192, 98, 1, 240, 247, 3, 173, 10, 247, 168, 30, 251, 102, 82, 143, 186, 198, 30, 187, 153, 159, 224, 235, 104, 234, 165, 46, 87, 132, 233, 224, 217, 83, 11, 239, 97, 240, 67, 134, 222, 137, 223, 89, 179, 199, 91, 38, 19, 53, 124, 153, 76, 156, 123, 255, 69, 102, 225, 177, 116, 210, 74, 208, 204, 247, 1, 254, 103, 77, 197, 197, 91, 223, 252, 63, 108, 15, 220, 180, 144, 134, 152, 84, 249, 99, 136, 197, 48, 212, 18, 245, 166, 8, 81, 175, 8, 203, 203, 30, 86, 188, 195, 130, 163, 202, 185, 235, 8, 210, 177, 141, 37, 64, 54, 80, 94, 187, 232, 68, 223, 82, 12, 199, 132, 146, 43, 114, 169, 188, 224, 117, 148, 170, 57, 203, 215, 109, 163, 27, 200, 115, 212, 101, 158, 181, 151, 204, 105, 49, 67, 86, 14, 147, 216, 6, 114, 25, 35, 0, 146, 120, 197, 60, 9, 2, 141, 151, 98, 248, 134, 188, 32, 12, 55, 109, 48, 108, 75, 193, 36, 64, 81, 97, 14, 239, 44, 131, 252, 231, 7, 207, 195, 134, 195, 67, 101, 195, 53, 137, 164, 235, 37, 202, 66, 38, 180, 18, 129, 44, 108, 95, 106, 200, 182, 197, 83, 158, 118, 105, 105, 143, 109, 237, 241, 6, 114, 119, 246, 205, 243, 210, 143, 152, 148, 174, 130, 166, 9, 110, 23, 51, 59, 88, 11, 129, 202, 244, 56, 71, 43, 72, 70, 217, 251, 179, 21, 216, 70, 82, 78, 112, 160, 138, 222, 110, 59, 64, 191, 73, 228, 176, 88, 39, 167, 183, 78, 24, 85, 252, 80, 83, 127, 15, 28, 254, 157, 139, 75, 203, 180, 122, 174, 188, 3, 104, 1, 173, 34, 215, 0, 37, 103, 118, 9, 136, 190, 36, 151, 173, 89, 85, 187, 229, 67, 252, 69, 244, 240, 162, 18, 171, 230, 71, 27, 144, 226, 42, 64, 206, 192, 6, 195, 114, 15, 94, 205, 66, 182, 200, 76, 13, 171, 95, 228, 248, 137, 180, 93, 182, 166, 102, 191, 2, 5, 95, 235, 107, 233, 35, 181, 132, 36, 250, 21, 10, 118, 29, 48, 51, 171, 207, 205, 4, 248, 145, 144, 11, 117, 20, 228, 194, 208, 187, 61, 132, 142, 248, 42, 122, 222, 45, 56, 4, 85, 145, 90, 144, 237, 206, 9, 21, 231, 31, 216, 234, 92, 147, 17, 61, 151, 149, 91, 160, 175, 255, 72, 168, 139, 136, 53, 10, 98, 244, 245, 69, 230, 73, 157, 24, 44, 51, 102, 217, 250, 116, 184, 151, 199, 253, 10, 97, 90, 163, 90, 141, 13, 61, 216, 209, 188, 56, 173, 75, 155, 162, 119, 224, 241, 198, 51, 73, 228, 98, 167, 19, 166, 247, 3, 88, 90, 246, 11, 136, 21, 243, 28, 171, 86, 11, 184, 247, 101, 56, 98, 220, 149, 108, 145, 136, 43, 193, 120, 139, 59, 98, 11, 118, 64, 145, 77, 23, 147, 165, 251, 164, 2, 6, 202, 210, 140, 59, 78, 120, 109, 142, 186, 244, 222, 62, 76, 44, 112, 146, 188, 83, 50, 139, 219, 133, 137, 114, 72, 196, 248, 32, 34, 102, 199, 98, 20, 248, 186, 154, 129, 211, 7, 129, 81, 176, 85, 43, 162, 170, 8, 28, 160, 80, 84, 21, 240, 142, 225, 173, 46, 29, 135, 48, 153, 161, 156, 253, 107, 72, 149, 43, 155, 135, 202, 101, 51, 249, 8, 101, 7, 150, 181, 89, 226, 59, 243, 3, 208, 175, 250, 20, 92, 231, 93, 74, 8, 43, 3, 114, 126, 156, 122, 178, 177, 157, 242, 30, 98, 80, 102, 40, 64, 111, 186, 242, 2, 31, 226, 161, 139, 211, 51, 145, 228, 5, 48, 235, 94, 198, 188, 225, 99, 146, 107, 19, 74, 54, 251, 220, 190, 162, 44, 203, 245, 238, 202, 137, 64, 85, 109, 153, 69, 232, 234, 189, 160, 202, 145, 153, 164, 189, 222, 169, 148, 90, 121, 49, 155, 113, 136, 240, 60, 177, 116, 87, 53, 32, 17, 126, 130, 173, 101, 101, 241, 198, 222, 46, 219, 117, 109, 87, 135, 158, 91, 195, 168, 249, 185, 12, 159, 170, 213, 220, 50, 27, 244, 13, 98, 68, 18, 6, 232, 168, 25, 120, 10, 172, 207, 255, 196, 173, 93, 235, 157, 23, 12, 188, 74, 235, 247, 106, 51, 166, 190, 120, 239, 103, 112, 151, 113, 149, 249, 88, 54, 47, 164, 248, 51, 109, 204, 75, 235, 27, 119, 114, 96, 158, 50, 140, 146, 237, 194, 44, 55, 91, 140, 25, 159, 57, 127, 46, 1, 68, 217, 243, 9, 213, 166, 145, 123, 241, 3, 26, 21, 137, 209, 235, 240, 131, 66, 29, 5, 132, 171, 16, 209, 252, 105, 4, 136, 113, 91, 237, 160, 209, 195, 205, 16, 239, 43, 77, 150, 196, 202, 47, 62, 98, 171, 238, 143, 57, 239, 56, 147, 220, 68, 224, 34, 119, 230, 82, 78, 22, 25, 217, 161, 15, 82, 43, 2, 107, 231, 15, 33, 213, 157, 171, 6, 36, 73, 204, 169, 67, 51, 75, 135, 173, 56, 124, 25, 176, 180, 200, 117, 134, 44, 117, 191, 81, 152, 124, 175, 78, 53, 93, 21, 13, 105, 84, 231, 72, 0, 152, 136, 99, 157, 94, 157, 102, 37, 223, 158, 82, 248, 7, 192, 47, 21, 166, 166, 74, 230, 22, 85, 49, 111, 90, 176, 9, 192, 220, 187, 236, 126, 155, 123, 152, 52, 88, 83, 129, 101, 119, 93, 63, 245, 214, 211, 14, 233, 133, 201, 201, 19, 89, 192, 197, 33, 187, 127, 222, 153, 93, 64, 126, 188, 134, 138, 113, 36, 127, 178, 255, 149, 89, 125, 237, 144, 249, 105, 85, 102, 245, 92, 84, 150, 148, 52, 235, 142, 92, 198, 156, 159, 129, 241, 158, 90, 26, 170, 199, 141, 172, 71, 183, 157, 61, 52, 205, 103, 204, 73, 245, 34, 34, 209, 188, 83, 194, 29, 157, 146, 46, 219, 120, 89, 231, 253, 35, 244, 245, 191, 199, 57, 4, 136, 246, 216, 112, 218, 101, 56, 247, 68, 54, 189, 34, 56, 211, 19, 147, 203, 223, 97, 86, 174, 155, 30, 231, 179, 99, 222, 229, 238, 65, 136, 46, 179, 183, 248, 196, 237, 233, 18, 81, 128, 64, 127, 230, 228, 27, 166, 51, 99, 147, 60, 142, 158, 33, 46, 219, 75, 33, 228, 85, 155, 48, 71, 146, 148, 77, 107, 208, 242, 40, 56, 225, 106, 157, 46, 122, 134, 46, 189, 216, 18, 22, 219, 125, 109, 45, 116, 163, 199, 217, 153, 248, 98, 133, 111, 100, 142, 89, 112, 113, 226, 122, 162, 145, 49, 229, 149, 58, 194, 200, 28, 200, 13, 221, 193, 112, 28, 177, 57, 198, 215, 230, 125, 222, 68, 92, 65, 36, 143, 12, 188, 93, 39, 125, 51, 184, 114, 22, 234, 253, 157, 213, 5, 184, 164, 61, 212, 198, 75, 201, 167, 10, 176, 187, 151, 132, 1, 231, 219, 62, 179, 236, 251, 133, 3, 47, 69, 190, 23, 17, 122, 163, 30, 210, 231, 198, 188, 61, 21, 129, 201, 201, 115, 95, 75, 82, 96, 213, 186, 217, 74, 51, 227, 23, 96, 89, 59, 8, 161, 203, 139, 68, 61, 214, 17, 178, 247, 103, 208, 36, 229, 4, 221, 83, 226, 82, 154, 93, 174, 60, 57, 119, 70, 236, 37, 67, 184, 163, 13, 206, 247, 244, 167, 0, 172, 9, 121, 177, 45, 191, 43, 252, 236, 152, 201, 98, 4, 46, 146, 20, 39, 7, 165, 92, 161, 192, 136, 51, 214, 202, 54, 69, 125, 212, 238, 140, 54, 189, 171, 43, 83, 39, 127, 26, 155, 227, 44, 34, 68, 97, 119, 30, 135, 37, 106, 174, 130, 130, 114, 146, 144, 41, 42, 78, 30, 100, 147, 129, 87, 215, 194, 196, 20, 76, 40, 255, 77, 62, 16, 98, 62, 79, 74, 239, 113, 112, 144, 9, 189, 209, 151, 168, 91, 111, 138, 136, 205, 6, 29, 42, 53, 155, 99, 226, 141, 128, 198, 90, 76, 179, 60, 108, 228, 35, 64, 30, 77, 90, 77, 136, 220, 36, 68, 20, 128, 113, 92, 44, 196, 212, 132, 88, 195, 146, 210, 64, 225, 59, 191, 51, 209, 229, 15, 238, 98, 222, 83, 247, 93, 99, 169, 138, 83, 33, 188, 141, 237, 172, 189, 118, 211, 119, 36, 92, 22, 111, 38, 129, 28, 5, 201, 247, 253, 103, 115, 195, 136, 95, 58, 20, 89, 172, 203, 199, 17, 85, 244, 24, 7, 9, 52, 209, 41, 190, 92, 164, 241, 39, 29, 253, 12, 248, 220, 123, 62, 255, 172, 107, 220, 108, 238, 170, 34, 89, 173, 90, 175, 108, 89, 122, 62, 145, 220, 202, 200, 31, 126, 49, 33, 100, 31, 65, 164, 118, 192, 45, 221, 61, 26, 47, 67, 122, 250, 91, 245, 89, 88, 45, 180, 99, 22, 58, 223, 49, 69, 247, 204, 149, 245, 124, 124, 248, 82, 110, 246, 41, 44, 174, 11, 54, 227, 51, 113, 247, 54, 181, 60, 248, 186, 216, 196, 152, 191, 117, 3, 153, 200, 234, 203, 80, 55, 147, 119, 55, 253, 63, 133, 83, 243, 78, 151, 149, 15, 191, 243, 226, 219, 211, 231, 195, 253, 91, 65, 71, 9, 148, 67, 151, 66, 212, 101, 210, 32, 139, 19, 166, 195, 228, 145, 72, 240, 20, 144, 86, 234, 225, 121, 245, 156, 79, 165, 100, 100, 209, 9, 10, 184, 120, 73, 145, 131, 235, 56, 204, 34, 55, 164, 187, 233, 198, 118, 169, 92, 245, 12, 160, 99, 61, 0, 243, 112, 142, 190, 104, 225, 227, 139, 115, 253, 211, 123, 239, 231, 172, 249, 52, 2, 134, 144, 246, 178, 177, 153, 187, 143, 108, 87, 20, 155, 180, 92, 199, 110, 96, 32, 2, 32, 38, 180, 178, 160, 253, 221, 82, 126, 228, 163, 154, 109, 210, 209, 38, 94, 149, 93, 249, 9, 93, 179, 177, 153, 131, 33, 79, 112, 14, 103, 36, 35, 146, 64, 92, 0, 173, 176, 61, 93, 178, 53, 79, 234, 33, 233, 88, 16, 58, 68, 173, 106, 245, 63, 9, 191, 169, 246, 180, 121, 237, 67, 24, 38, 54, 99, 77, 216, 103, 86, 217, 56, 218, 65, 163, 55, 175, 0, 55, 201, 150, 6, 166, 164, 126, 11, 46, 75, 203, 151, 134, 20, 153, 75, 4, 61, 205, 9, 75, 160, 11, 38, 214, 150, 202, 199, 241, 169, 82, 228, 168, 232, 203, 11, 123, 186, 9, 3, 14, 143, 15, 50, 150, 219, 91, 122, 36, 148, 117, 57, 237, 150, 64, 8, 10, 187, 174, 73, 104, 124, 152, 166, 177, 152, 112, 210, 61, 56, 229, 223, 90, 236, 233, 112, 80, 157, 88, 215, 9, 146, 12, 120, 133, 22, 198, 90, 116, 174, 183, 228, 243, 49, 192, 134, 43, 249, 79, 78, 131, 143, 6, 248, 28, 118, 44, 93, 25, 182, 120, 189, 81, 52, 158, 51, 218, 38, 207, 195, 92, 88, 241, 105, 103, 166, 36, 131, 130, 57, 69, 254, 144, 138, 45, 59, 201, 246, 131, 187, 232, 54, 89, 121, 177, 234, 77, 103, 11, 122, 110, 181, 129, 104, 133, 17, 95, 18, 84, 40, 45, 115, 144, 125, 50, 231, 27, 153, 217, 172, 247, 10, 198, 67, 54, 28, 250, 233, 67, 186, 26, 244, 14, 24, 127, 158, 187, 12, 46, 201, 23, 183, 95, 5, 212, 86, 222, 132, 150, 171, 106, 194, 52, 207, 47, 7, 156, 255, 230, 69, 1, 108, 250, 38, 92, 34, 2, 249, 20, 204, 136, 236, 69, 70, 205, 151, 7, 109, 31, 205, 255, 76, 151, 43, 224, 164, 55, 155, 254, 158, 142, 123, 163, 249, 95, 132, 239, 68, 243, 143, 47, 233, 84, 72, 207, 50, 6, 198, 58, 45, 95, 108, 237, 189, 91, 120, 30, 148, 221, 65, 48, 51, 151, 33, 4, 157, 225, 175, 190, 67, 42, 34, 125, 67, 169, 10, 179, 85, 16, 253, 229, 103, 174, 8, 168, 1, 133, 245, 54, 181, 66, 29, 28, 178, 131, 220, 211, 192, 80, 164, 131, 44, 163, 101, 213, 201, 49, 77, 197, 136, 30, 55, 89, 29, 109, 61, 51, 207, 208, 192, 130, 241, 228, 246, 87, 233, 53, 64, 246, 240, 139, 65, 49, 148, 101, 147, 89, 171, 88, 82, 223, 35, 11, 155, 231, 27, 33, 129, 6, 76, 254, 188, 104, 225, 39, 122, 62, 172, 66, 156, 32, 114, 91, 208, 186, 230, 78, 139, 27, 233, 241, 42, 172, 155, 248, 33, 125, 49, 234, 182, 219, 178, 5, 175, 104, 184, 32, 193, 191, 161, 101, 208, 191, 248, 222, 217, 86, 39, 171, 32, 147, 132, 170, 139, 17, 131, 63, 33, 151, 15, 158, 48, 94, 111, 60, 56, 144, 215, 44, 200, 20, 241, 124, 137, 34, 188, 251, 81, 152, 204, 224, 97]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eRvwZ5Nf7g6"
      },
      "source": [
        "k = 8       # Number of information bits per message, i.e., M=2**k\n",
        "n = 4       # Number of real channel uses per message\n",
        "seed = 2    # Seed RNG reproduce identical results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28KCbvYif7hD"
      },
      "source": [
        "#### The Autoencoder Class\n",
        "In order to quickly experiment with different architecture and parameter choices, it is useful to create a Python class that has functions for training and inference. Each autoencoder instance has its own Tensorflow session and graph. Thus, you can have multiple instances running at the same time without interference between them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs9Rtd01f7hG"
      },
      "source": [
        "\n",
        "class AE(object):\n",
        "    def __init__(self, k, n, seed=None, filename=None):\n",
        "        assert (n%2 == 0), \"Channel only allows complex symbols -> n must be a multiple of 2\"\n",
        "        self.k = k \n",
        "        self.n = n\n",
        "        self.n_complex = int(self.n/2)\n",
        "        self.bits_per_symbol = self.k/self.n_complex\n",
        "        self.M = 2**self.k\n",
        "        self.seed = seed if (seed is not None) else int(time.time())           \n",
        "        self.graph = None\n",
        "        self.sess = None   \n",
        "        self.vars = None\n",
        "        self.saver = None   \n",
        "        self.constellations = None\n",
        "        self.blers = None\n",
        "        self.create_graph()\n",
        "        self.create_session()\n",
        "        if filename is not None:    \n",
        "            self.load(filename)       \n",
        "        return\n",
        "    \n",
        "    def generate_distances(self,int_batch_size,bins):\n",
        "        # int_batch_size: 1000\n",
        "        # bins = np.array([0, 1, 2, 3, 4, 5, 6])\n",
        "\n",
        "        t = np.linspace(0,1,int_batch_size)\n",
        "        triangle1 = signal.sawtooth(2 * np.pi * 5 * t, 0.5)\n",
        "        triangle1 = 10*triangle1\n",
        "        triangle1 = triangle1.clip(min=0)\n",
        "\n",
        "        triangle2 = signal.sawtooth(5 * np.pi * 5 * t, 0.5)\n",
        "        triangle2 = 10*triangle2\n",
        "        triangle2 = triangle2.clip(min=0)\n",
        "\n",
        "        triangle3 = triangle1 + triangle2\n",
        "        triangle3 = triangle3/15*(7)\n",
        "        #print(s)\n",
        "\n",
        "        bins = np.array([0, 1, 2, 3, 4, 5, 6])\n",
        "        tr = np.digitize(triangle3, bins, right=True)\n",
        "        replacements = {0:7, 1:6, 2:5, 3:4, 4:3, 5:2, 6:1, 7:0}\n",
        "        replacer = replacements.get\n",
        "        tr = ([replacer(n, n) for n in tr])\n",
        "     \n",
        "        return tr\n",
        "\n",
        "\n",
        "    \n",
        "    def create_graph(self):\n",
        "        '''This function creates the computation graph of the autoencoder'''\n",
        "        self.graph = tf.Graph()        \n",
        "        with self.graph.as_default():    \n",
        "            tf.set_random_seed(self.seed)\n",
        "            batch_size = tf.placeholder(tf.int32, shape=())\n",
        "            \n",
        "            # Transmitter\n",
        "            #s = tf.random_uniform(shape=[batch_size], minval=0, maxval=self.M, dtype=tf.int64)\n",
        "            #s = tf.random_uniform(shape=[1000], minval=0, maxval=self.M, dtype=tf.int64)\n",
        "            s = tf.cast(tf.floor(tf.linspace(0.0, M, batch_size, name=\"linspace\")), tf.int64)\n",
        "            \n",
        "            #s = tf.random_uniform(shape=[1000], minval=0, maxval=self.M, dtype=tf.int64)\n",
        "            \n",
        "            #plt.plot(t, triangle3, 'o')\n",
        "            #plt.plot(t, triangle3)\n",
        "            #print(s)\n",
        "            #plt.plot(t, s)\n",
        "            #s = tf.convert_to_tensor(s, dtype=tf.int64)\n",
        "            x = self.encoder(s)     \n",
        "            \n",
        "            # Channel\n",
        "            noise_std = tf.placeholder(tf.float32, shape=())\n",
        "            ad_noise_std = (tf.linspace(0.0, noise_std, batch_size, name=\"linspace\"))\n",
        "            noise = tf.random_normal([batch_size], mean=0.0, stddev=ad_noise_std)\n",
        "            #x = self.encoder(s)     \n",
        "            \n",
        "            # Channel\n",
        "            #noise_std = tf.placeholder(tf.float32, shape=())\n",
        "            #noise = tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std) \n",
        "\n",
        "            fade = tf.random.normal(shape=tf.shape(x))\n",
        "            sparr1,sparr2 = tf.split(fade,num_or_size_splits=2, axis=2)\n",
        "            complex_fade = tf.complex(sparr1, sparr2)\n",
        "            fade = tf.abs(complex_fade)\n",
        "            #fade = tf.math.sqrt(1/2)*fade\n",
        "\n",
        "            #fade = 1\n",
        "            y = tf.multiply(x,fade) + noise\n",
        "            \n",
        "           \n",
        "            # Receiver\n",
        "            s_hat = self.decoder(y)\n",
        "            correct_s_hat = tf.argmax(tf.nn.softmax(s_hat), axis=1)\n",
        "\n",
        "            cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=s, logits=s_hat)\n",
        "            #cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=s, logits=s_hat, weights= (s+1)**(4))\n",
        "\n",
        "\n",
        "            correct_predictions = tf.equal(tf.argmax(tf.nn.softmax(s_hat), axis=1), s)\n",
        "            accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
        "            bler = 1-accuracy\n",
        "\n",
        "            # Optimizer\n",
        "            lr = tf.placeholder(tf.float32, shape=()) # We can feed in any desired learning rate for each step     \n",
        "            train_op = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
        "            #train_op_0 = tf.train.AdamOptimizer(lr).minimize(cross_entropy_0)\n",
        "            #lr = tf.train.exponential_decay(1e-10, global_step=cross_entropy, decay_steps=100, decay_rate=1.30)\n",
        "\n",
        "        \n",
        "            # References to graph variables we need to access later \n",
        "            self.vars = {\n",
        "                'accuracy': accuracy,\n",
        "                'batch_size': batch_size,\n",
        "                'bler': bler,\n",
        "                'cross_entropy': cross_entropy,\n",
        "                'init': tf.global_variables_initializer(),\n",
        "                'lr': lr,\n",
        "                'noise_std': noise_std,\n",
        "                'train_op': train_op,\n",
        "                's': s,\n",
        "                's_hat': s_hat,\n",
        "                'correct_s_hat': correct_s_hat,\n",
        "                'x': x,\n",
        "            }            \n",
        "            self.saver = tf.train.Saver()\n",
        "        return\n",
        "    \n",
        "    def create_session(self):\n",
        "        '''Create a session for the autoencoder instance with the compuational graph'''\n",
        "        self.sess = tf.Session(graph=self.graph)        \n",
        "        self.sess.run(self.vars['init'])\n",
        "        return\n",
        "    \n",
        "    def encoder(self, input):\n",
        "        '''The transmitter'''\n",
        "        self.weight_var_rec = self.weight_variable((self.M,self.M)) # shape = (8,8)\n",
        "        self.embedding_lookup_rec = tf.nn.embedding_lookup(self.weight_var_rec, input)\n",
        "        print(self.embedding_lookup_rec)\n",
        "        x = tf.nn.elu(self.embedding_lookup_rec)\n",
        "        #x = tf.layers.dense(self.embedding_lookup_rec, self.M, activation=tf.nn.relu)\n",
        "        x = tf.layers.dense(x, self.M, activation=None)\n",
        "        x = tf.layers.dense(x, self.n, activation=None)\n",
        "        #x = tf.layers.dense(x, self.n, activation=None)\n",
        "        #x = tf.layers.dense(x, self.n, activation=None)\n",
        "        #x = tf.layers.dense(x, self.n, activation=None)\n",
        "        #x = tf.layers.dense(x, self.n, activation=None)\n",
        "        x = tf.reshape(x, shape=[-1,self.n_complex,2])\n",
        "        print(x);\n",
        "        #Average power normalization\n",
        "        x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) \n",
        "        return x\n",
        "    \n",
        "    def decoder(self, input):\n",
        "        '''The Receiver'''\n",
        "        #input = self.flip_decoder(input)\n",
        "        y = tf.reshape(input, shape=[-1,self.n])\n",
        "        y = tf.layers.dense(y, self.M, activation=None)\n",
        "        y = tf.layers.dense(y, self.M, activation=None)\n",
        "        y = tf.layers.dense(y, self.M, activation=None)\n",
        "        #y = tf.layers.dense(y, self.M, activation=None)\n",
        "        #y = tf.layers.dense(y, self.M, activation=None)\n",
        "        #y = tf.layers.dense(y, self.M, activation=None)\n",
        "        #y = tf.layers.dense(y, self.M, activation=None)\n",
        "        #y = tf.layers.dense(y, self.M, activation=None)\n",
        "        print(y);\n",
        "        return y\n",
        "    \n",
        "    def EbNo2Sigma(self, ebnodb):\n",
        "        '''Convert Eb/No in dB to noise standard deviation'''\n",
        "        ebno = 10**(ebnodb/10)\n",
        "        return 1/np.sqrt(2*self.bits_per_symbol*ebno)\n",
        "    \n",
        "    def gen_feed_dict(self, batch_size, ebnodb, lr):\n",
        "        '''Generate a feed dictionary for training and validation'''        \n",
        "        return {\n",
        "            self.vars['batch_size']: batch_size,\n",
        "            self.vars['noise_std']: self.EbNo2Sigma(ebnodb),\n",
        "            self.vars['lr']: lr,\n",
        "        }\n",
        "\n",
        "    def gen_e2e_feed_dict(self, batch_size, ebnodb, s_input):\n",
        "        '''Generate a feed dictionary for training and validation'''        \n",
        "        return {\n",
        "            self.vars['batch_size']: batch_size,\n",
        "            self.vars['noise_std']: self.EbNo2Sigma(ebnodb),\n",
        "            self.vars['s']: s_input,\n",
        "        }   \n",
        "    \n",
        "    def load(self, filename):\n",
        "        '''Load an pre_trained model'''\n",
        "        return self.saver.restore(self.sess, filename)\n",
        "        \n",
        "    def plot_constellation(self, maxrange=None):\n",
        "        '''Generate a plot of the current constellation'''\n",
        "        x = self.transmit(range(self.M))\n",
        "        if (maxrange is None):\n",
        "            maxrange = np.max(np.abs(x))\n",
        "        for k in range(self.n_complex):\n",
        "            image = plt.figure(figsize=(6,6))\n",
        "            plt.grid(True)\n",
        "            plt.xlim(-maxrange,maxrange)\n",
        "            plt.ylim(-maxrange,maxrange)\n",
        "            for i in range(self.M):       \n",
        "                plt.scatter(x[i,k,0],x[i,k,1],c=\"black\",marker='x')   \n",
        "            image.axes[0].set_xticks(np.array([-2,-1,0,1,2]))\n",
        "            image.axes[0].set_yticks(np.array([-2,-1,0,1,2]))\n",
        "            image.suptitle('%d. complex symbol' % (k+1))\n",
        "            plt.xlabel('Re')\n",
        "            plt.ylabel('Im')\n",
        "        return x, image\n",
        "    \n",
        "    def save(self, filename):\n",
        "        '''Save the current model'''\n",
        "        return self.saver.save(self.sess, filename)  \n",
        "    \n",
        "    def test_step(self, batch_size, ebnodb):\n",
        "        '''Compute the BLER over a single batch and Eb/No'''\n",
        "        bler = self.sess.run(self.vars['bler'], feed_dict=self.gen_feed_dict(batch_size, ebnodb, lr=0))\n",
        "        return bler\n",
        "    \n",
        "    def transmit(self, s):\n",
        "        '''Returns the transmitted sigals corresponding to message indices'''\n",
        "        return self.sess.run(self.vars['x'], feed_dict={self.vars['s']: s})\n",
        "\n",
        "    def end2end(self, batch_size, ebnodb, input_s):\n",
        "        '''Returns the transmitted sigals corresponding to message indices'''\n",
        "        return self.sess.run(self.vars['correct_s_hat'], feed_dict=self.gen_e2e_feed_dict(batch_size, ebnodb, input_s)) \n",
        "        #print(self.sess.run(self.vars['correct_s_hat'], feed_dict={self.vars['s']: input_s}))     \n",
        "\n",
        "    #print(self.sess.run(self.vars['s_hat'], feed_dict={self.vars['s']: s}))\n",
        "\n",
        "    def train(self, training_params, validation_params):  \n",
        "        #s_input = self.generate_distances(100,np.array([0, 1, 2, 3, 4, 5, 6]))\n",
        "        \n",
        "        '''Training and validation loop'''\n",
        "        for index, params in enumerate(training_params):            \n",
        "            batch_size, lr, ebnodb, iterations = params            \n",
        "            print('\\nBatch Size: ' + str(batch_size) +\n",
        "                  ', Learning Rate: ' + str(lr) +\n",
        "                  ', EbNodB: ' + str(ebnodb) +\n",
        "                  ', Iterations: ' + str(iterations))\n",
        "            \n",
        "            val_size, val_ebnodb, val_steps = validation_params[index]\n",
        "            \n",
        "            for i in range(iterations):\n",
        "                self.train_step(batch_size, ebnodb, lr)    \n",
        "                if (i%val_steps==0):\n",
        "                    #bler = self.sess.run(self.vars['bler'], feed_dict=self.gen_new_feed_dict(val_size, val_ebnodb, lr, s_input))\n",
        "                    bler = self.sess.run(self.vars['bler'], feed_dict=self.gen_feed_dict(val_size, val_ebnodb, lr))\n",
        "                    print(bler)                           \n",
        "        return       \n",
        "    \n",
        "    def train_step(self, batch_size, ebnodb, lr):\n",
        "        '''A single training step'''\n",
        "        #self.sess.run(self.vars['train_op'], feed_dict=self.gen_new_feed_dict(batch_size, ebnodb, lr, s_input))\n",
        "        self.sess.run(self.vars['train_op'], feed_dict=self.gen_feed_dict(batch_size, ebnodb, lr))\n",
        "        return \n",
        "    \n",
        "    def weight_variable(self, shape):\n",
        "        '''Xavier-initialized weights optimized for ReLU Activations'''\n",
        "        (fan_in, fan_out) = shape\n",
        "        low = np.sqrt(6.0/(fan_in + fan_out)) \n",
        "        high = -np.sqrt(6.0/(fan_in + fan_out))\n",
        "        return tf.Variable(tf.random_uniform(shape, minval=low, maxval=high, dtype=tf.float32))\n",
        "    \n",
        "    def bler_sim(self, ebnodbs, batch_size, iterations):\n",
        "        '''Monte Carlo simulations of BLER for a range of Eb/No\n",
        "           Sometimes we to compute statistics for batch sizes that do not fit into the GPUs memory.\n",
        "           You can average over multiple batches with small size instead.           \n",
        "        '''\n",
        "        BLER = np.zeros_like(ebnodbs)\n",
        "        for i in range(iterations):\n",
        "            bler = np.array([self.sess.run(self.vars['bler'],\n",
        "                            feed_dict=self.gen_feed_dict(batch_size, ebnodb, lr=0)) for ebnodb in ebnodbs])\n",
        "            BLER = BLER + bler/iterations\n",
        "        return BLER\n",
        "    \n",
        "    def plot_bler(self, EbNodB, BLER):\n",
        "        '''Plot a BLER curve'''\n",
        "        image = plt.figure(figsize=(10,8))\n",
        "        plt.plot(EbNodB, BLER, '-r', linewidth=2.0)\n",
        "        plt.yscale('log')\n",
        "        plt.xlabel('EbNo (dB)', fontsize=18)\n",
        "        plt.ylabel('Block-error rate', fontsize=18)\n",
        "        plt.grid(True)\n",
        "        plt.ylim([1e-5,1])\n",
        "        return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bANUdLIsf7hM"
      },
      "source": [
        "## Training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YeHghWVRf7hO",
        "outputId": "d7960470-4c0e-4f5d-c50e-c907f74fb901"
      },
      "source": [
        "train_EbNodB = 40\n",
        "val_EbNodB = train_EbNodB\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "\n",
        "#epoch = [10000]\n",
        "\n",
        "#for i in epoch:\n",
        "training_params = [\n",
        "    #batch_size, lr, ebnodb, iterations\n",
        "    [10000 , lr, train_EbNodB, 10000]\n",
        "    ]\n",
        "\n",
        "validation_params = [\n",
        "    #batch_size, ebnodb, val_steps \n",
        "    [10000, val_EbNodB, 1000],\n",
        "    [10000, val_EbNodB, 1000],\n",
        "    [10000, val_EbNodB, 1000]\n",
        "    ]\n",
        "\n",
        "model_file_uw = 'models/ae_k_{}_n_{}'.format(k,n)\n",
        "ae = AE(k,n,seed)\n",
        "ae.train(training_params, validation_params)\n",
        "ae.save(model_file_uw);\n",
        "ae = AE(k,n,seed, filename=model_file_uw)\n",
        "  #ae.plot_constellation();\n",
        "  #ae.end2end(tr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"embedding_lookup/Identity:0\", shape=(?, 256), dtype=float32)\n",
            "Tensor(\"Reshape:0\", shape=(?, 2, 2), dtype=float32)\n",
            "Tensor(\"dense_4/BiasAdd:0\", shape=(?, 256), dtype=float32)\n",
            "\n",
            "Batch Size: 10000, Learning Rate: 0.01, EbNodB: 40, Iterations: 10000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [10000,2,2] vs. [10000]\n\t [[{{node add}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-420e5c5597cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel_file_uw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'models/ae_k_{}_n_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file_uw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_file_uw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-58bbf81a9b8f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_params, validation_params)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mebnodb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                     \u001b[0;31m#bler = self.sess.run(self.vars['bler'], feed_dict=self.gen_new_feed_dict(val_size, val_ebnodb, lr, s_input))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-58bbf81a9b8f>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, batch_size, ebnodb, lr)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;34m'''A single training step'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;31m#self.sess.run(self.vars['train_op'], feed_dict=self.gen_new_feed_dict(batch_size, ebnodb, lr, s_input))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_op'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mebnodb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [10000,2,2] vs. [10000]\n\t [[node add (defined at /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'add':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-54-420e5c5597cf>\", line 23, in <module>\n    ae = AE(k,n,seed)\n  File \"<ipython-input-53-58bbf81a9b8f>\", line 17, in __init__\n    self.create_graph()\n  File \"<ipython-input-53-58bbf81a9b8f>\", line 88, in create_graph\n    y = tf.multiply(x,fade) + noise\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_ops.py\", line 899, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_ops.py\", line 1197, in _add_dispatch\n    return gen_math_ops.add_v2(x, y, name=name)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/gen_math_ops.py\", line 549, in add_v2\n    \"AddV2\", x=x, y=y, name=name)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl3hENsvf7hW"
      },
      "source": [
        "## Create and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0GA7ihjf7hZ"
      },
      "source": [
        "#model_file = 'models/ae_k_{}_n_{}'.format(k,n)\n",
        "#ae = AE(k,n,seed)\n",
        "#ae.train(training_params, validation_params)\n",
        "#ae.save(model_file); # Save the trained autoencoder if you want to reuse it later\n",
        "#sess = tf.Session()\n",
        "#print(sess.run((rmse_uw_0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzqpcwGaf7hm"
      },
      "source": [
        "## Evaluate trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y33vV4xKf7hn"
      },
      "source": [
        "ae_uw = AE(k,n,seed, filename=model_file_uw) #Load a pretrained model that you have saved if needed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fasS-Rz1lapW"
      },
      "source": [
        "\n",
        "class AE_Weighted(object):\n",
        "    def __init__(self, k, n, seed=None, filename=None):\n",
        "        assert (n%2 == 0), \"Channel only allows complex symbols -> n must be a multiple of 2\"\n",
        "        self.k = k \n",
        "        self.n = n\n",
        "        self.n_complex = int(self.n/2)\n",
        "        self.bits_per_symbol = self.k/self.n_complex\n",
        "        self.M = 2**self.k\n",
        "        self.seed = seed if (seed is not None) else int(time.time())           \n",
        "        self.graph = None\n",
        "        self.sess = None   \n",
        "        self.vars = None\n",
        "        self.saver = None   \n",
        "        self.constellations = None\n",
        "        self.blers = None\n",
        "        self.create_graph()\n",
        "        self.create_session()\n",
        "        if filename is not None:    \n",
        "            self.load(filename)       \n",
        "        return\n",
        "    \n",
        "    def generate_distances(self,int_batch_size,bins):\n",
        "        # int_batch_size: 1000\n",
        "        # bins = np.array([0, 1, 2, 3, 4, 5, 6])\n",
        "\n",
        "        t = np.linspace(0,1,int_batch_size)\n",
        "        triangle1 = signal.sawtooth(2 * np.pi * 5 * t, 0.5)\n",
        "        triangle1 = 10*triangle1\n",
        "        triangle1 = triangle1.clip(min=0)\n",
        "\n",
        "        triangle2 = signal.sawtooth(5 * np.pi * 5 * t, 0.5)\n",
        "        triangle2 = 10*triangle2\n",
        "        triangle2 = triangle2.clip(min=0)\n",
        "\n",
        "        triangle3 = triangle1 + triangle2\n",
        "        triangle3 = triangle3/15*(7)\n",
        "        #print(s)\n",
        "\n",
        "        bins = np.array([0, 1, 2, 3, 4, 5, 6])\n",
        "        tr = np.digitize(triangle3, bins, right=True)\n",
        "        replacements = {0:7, 1:6, 2:5, 3:4, 4:3, 5:2, 6:1, 7:0}\n",
        "        replacer = replacements.get\n",
        "        tr = ([replacer(n, n) for n in tr])\n",
        "     \n",
        "        return tr\n",
        "\n",
        "\n",
        "    \n",
        "    def create_graph(self):\n",
        "        '''This function creates the computation graph of the autoencoder'''\n",
        "        self.graph = tf.Graph()        \n",
        "        with self.graph.as_default():    \n",
        "            tf.set_random_seed(self.seed)\n",
        "            batch_size = tf.placeholder(tf.int32, shape=())\n",
        "            \n",
        "            # Transmitter\n",
        "            #s = tf.random_uniform(shape=[batch_size], minval=0, maxval=self.M, dtype=tf.int64)\n",
        "            #s = tf.random_uniform(shape=[1000], minval=0, maxval=self.M, dtype=tf.int64)\n",
        "            s = tf.cast(tf.floor(tf.linspace(0.0, M, batch_size, name=\"linspace\")), tf.int64)            \n",
        "            #s = tf.random_uniform(shape=[1000], minval=0, maxval=self.M, dtype=tf.int64)\n",
        "            \n",
        "            #plt.plot(t, triangle3, 'o')\n",
        "            #plt.plot(t, triangle3)\n",
        "            #print(s)\n",
        "            #plt.plot(t, s)\n",
        "            #s = tf.convert_to_tensor(s, dtype=tf.int64)\n",
        "            x = self.encoder(s)     \n",
        "            \n",
        "            # Channel\n",
        "            noise_std = tf.placeholder(tf.float32, shape=())\n",
        "            ad_noise_std = (tf.linspace(0.0, noise_std, batch_size, name=\"linspace\"))\n",
        "            noise = tf.random_normal([batch_size], mean=0.0, stddev=ad_noise_std)\n",
        "            #x = self.encoder(s)     \n",
        "            \n",
        "            # Channel\n",
        "            #noise_std = tf.placeholder(tf.float32, shape=())\n",
        "            #noise = tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std) \n",
        "\n",
        "            fade = tf.random.normal(shape=tf.shape(x))\n",
        "            sparr1,sparr2 = tf.split(fade,num_or_size_splits=2, axis=2)\n",
        "            complex_fade = tf.complex(sparr1, sparr2)\n",
        "            fade = tf.abs(complex_fade)\n",
        "            #fade = tf.math.sqrt(1/2)*fade\n",
        "\n",
        "            #fade = 1\n",
        "            y = tf.multiply(x,fade) + noise\n",
        "            \n",
        "           \n",
        "            # Receiver\n",
        "            s_hat = self.decoder(y)\n",
        "            correct_s_hat = tf.argmax(tf.nn.softmax(s_hat), axis=1)\n",
        "\n",
        "            #cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=s, logits=s_hat)\n",
        "            cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=s, logits=s_hat, weights= (s+1)**(4))\n",
        "\n",
        "\n",
        "            correct_predictions = tf.equal(tf.argmax(tf.nn.softmax(s_hat), axis=1), s)\n",
        "            accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
        "            bler = 1-accuracy\n",
        "\n",
        "            # Optimizer\n",
        "            lr = tf.placeholder(tf.float32, shape=()) # We can feed in any desired learning rate for each step     \n",
        "            train_op = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
        "            #train_op_0 = tf.train.AdamOptimizer(lr).minimize(cross_entropy_0)\n",
        "            #lr = tf.train.exponential_decay(1e-10, global_step=cross_entropy, decay_steps=100, decay_rate=1.30)\n",
        "\n",
        "        \n",
        "            # References to graph variables we need to access later \n",
        "            self.vars = {\n",
        "                'accuracy': accuracy,\n",
        "                'batch_size': batch_size,\n",
        "                'bler': bler,\n",
        "                'cross_entropy': cross_entropy,\n",
        "                'init': tf.global_variables_initializer(),\n",
        "                'lr': lr,\n",
        "                'noise_std': noise_std,\n",
        "                'train_op': train_op,\n",
        "                's': s,\n",
        "                's_hat': s_hat,\n",
        "                'correct_s_hat': correct_s_hat,\n",
        "                'x': x,\n",
        "            }            \n",
        "            self.saver = tf.train.Saver()\n",
        "        return\n",
        "    \n",
        "    def create_session(self):\n",
        "        '''Create a session for the autoencoder instance with the compuational graph'''\n",
        "        self.sess = tf.Session(graph=self.graph)        \n",
        "        self.sess.run(self.vars['init'])\n",
        "        return\n",
        "    \n",
        "    def encoder(self, input):\n",
        "        '''The transmitter'''\n",
        "        self.weight_var_rec = self.weight_variable((self.M,self.M)) # shape = (8,8)\n",
        "        self.embedding_lookup_rec = tf.nn.embedding_lookup(self.weight_var_rec, input)\n",
        "        print(self.embedding_lookup_rec)\n",
        "        x = tf.nn.elu(self.embedding_lookup_rec)\n",
        "        #x = tf.layers.dense(self.embedding_lookup_rec, self.M, activation=tf.nn.relu)\n",
        "        x = tf.layers.dense(x, self.M, activation=None)\n",
        "        x = tf.layers.dense(x, self.n, activation=None)\n",
        "        #x = tf.layers.dense(x, self.n, activation=None)\n",
        "        #x = tf.layers.dense(x, self.n, activation=None)\n",
        "        #x = tf.layers.dense(x, self.n, activation=None)\n",
        "        #x = tf.layers.dense(x, self.n, activation=None)\n",
        "        x = tf.reshape(x, shape=[-1,self.n_complex,2])\n",
        "        print(x);\n",
        "        #Average power normalization\n",
        "        x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) \n",
        "        return x\n",
        "    \n",
        "    def decoder(self, input):\n",
        "        '''The Receiver'''\n",
        "        #input = self.flip_decoder(input)\n",
        "        y = tf.reshape(input, shape=[-1,self.n])\n",
        "        y = tf.layers.dense(y, self.M, activation=None)\n",
        "        y = tf.layers.dense(y, self.M, activation=None)\n",
        "        y = tf.layers.dense(y, self.M, activation=None)\n",
        "        #y = tf.layers.dense(y, self.M, activation=None)\n",
        "        #y = tf.layers.dense(y, self.M, activation=None)\n",
        "        #y = tf.layers.dense(y, self.M, activation=None)\n",
        "        #y = tf.layers.dense(y, self.M, activation=None)\n",
        "        #y = tf.layers.dense(y, self.M, activation=None)\n",
        "        print(y);\n",
        "        return y\n",
        "    \n",
        "    def EbNo2Sigma(self, ebnodb):\n",
        "        '''Convert Eb/No in dB to noise standard deviation'''\n",
        "        ebno = 10**(ebnodb/10)\n",
        "        return 1/np.sqrt(2*self.bits_per_symbol*ebno)\n",
        "    \n",
        "    def gen_feed_dict(self, batch_size, ebnodb, lr):\n",
        "        '''Generate a feed dictionary for training and validation'''        \n",
        "        return {\n",
        "            self.vars['batch_size']: batch_size,\n",
        "            self.vars['noise_std']: self.EbNo2Sigma(ebnodb),\n",
        "            self.vars['lr']: lr,\n",
        "        }\n",
        "\n",
        "    def gen_e2e_feed_dict(self, batch_size, ebnodb, s_input):\n",
        "        '''Generate a feed dictionary for training and validation'''        \n",
        "        return {\n",
        "            self.vars['batch_size']: batch_size,\n",
        "            self.vars['noise_std']: self.EbNo2Sigma(ebnodb),\n",
        "            self.vars['s']: s_input,\n",
        "        }   \n",
        "    \n",
        "    def load(self, filename):\n",
        "        '''Load an pre_trained model'''\n",
        "        return self.saver.restore(self.sess, filename)\n",
        "        \n",
        "    def plot_constellation(self, maxrange=None):\n",
        "        '''Generate a plot of the current constellation'''\n",
        "        x = self.transmit(range(self.M))\n",
        "        if (maxrange is None):\n",
        "            maxrange = np.max(np.abs(x))\n",
        "        for k in range(self.n_complex):\n",
        "            image = plt.figure(figsize=(6,6))\n",
        "            plt.grid(True)\n",
        "            plt.xlim(-maxrange,maxrange)\n",
        "            plt.ylim(-maxrange,maxrange)\n",
        "            for i in range(self.M):       \n",
        "                plt.scatter(x[i,k,0],x[i,k,1],c=\"black\",marker='x')   \n",
        "            image.axes[0].set_xticks(np.array([-2,-1,0,1,2]))\n",
        "            image.axes[0].set_yticks(np.array([-2,-1,0,1,2]))\n",
        "            image.suptitle('%d. complex symbol' % (k+1))\n",
        "            plt.xlabel('Re')\n",
        "            plt.ylabel('Im')\n",
        "        return x, image\n",
        "    \n",
        "    def save(self, filename):\n",
        "        '''Save the current model'''\n",
        "        return self.saver.save(self.sess, filename)  \n",
        "    \n",
        "    def test_step(self, batch_size, ebnodb):\n",
        "        '''Compute the BLER over a single batch and Eb/No'''\n",
        "        bler = self.sess.run(self.vars['bler'], feed_dict=self.gen_feed_dict(batch_size, ebnodb, lr=0))\n",
        "        return bler\n",
        "    \n",
        "    def transmit(self, s):\n",
        "        '''Returns the transmitted sigals corresponding to message indices'''\n",
        "        return self.sess.run(self.vars['x'], feed_dict={self.vars['s']: s})\n",
        "\n",
        "    def end2end(self, batch_size, ebnodb, input_s):\n",
        "        '''Returns the transmitted sigals corresponding to message indices'''\n",
        "        return self.sess.run(self.vars['correct_s_hat'], feed_dict=self.gen_e2e_feed_dict(batch_size, ebnodb, input_s)) \n",
        "        #print(self.sess.run(self.vars['correct_s_hat'], feed_dict={self.vars['s']: input_s}))     \n",
        "\n",
        "    #print(self.sess.run(self.vars['s_hat'], feed_dict={self.vars['s']: s}))\n",
        "\n",
        "    def train(self, training_params, validation_params):  \n",
        "        #s_input = self.generate_distances(100,np.array([0, 1, 2, 3, 4, 5, 6]))\n",
        "        \n",
        "        '''Training and validation loop'''\n",
        "        for index, params in enumerate(training_params):            \n",
        "            batch_size, lr, ebnodb, iterations = params            \n",
        "            print('\\nBatch Size: ' + str(batch_size) +\n",
        "                  ', Learning Rate: ' + str(lr) +\n",
        "                  ', EbNodB: ' + str(ebnodb) +\n",
        "                  ', Iterations: ' + str(iterations))\n",
        "            \n",
        "            val_size, val_ebnodb, val_steps = validation_params[index]\n",
        "            \n",
        "            for i in range(iterations):\n",
        "                self.train_step(batch_size, ebnodb, lr)    \n",
        "                if (i%val_steps==0):\n",
        "                    #bler = self.sess.run(self.vars['bler'], feed_dict=self.gen_new_feed_dict(val_size, val_ebnodb, lr, s_input))\n",
        "                    bler = self.sess.run(self.vars['bler'], feed_dict=self.gen_feed_dict(val_size, val_ebnodb, lr))\n",
        "                    print(bler)                           \n",
        "        return       \n",
        "    \n",
        "    def train_step(self, batch_size, ebnodb, lr):\n",
        "        '''A single training step'''\n",
        "        #self.sess.run(self.vars['train_op'], feed_dict=self.gen_new_feed_dict(batch_size, ebnodb, lr, s_input))\n",
        "        self.sess.run(self.vars['train_op'], feed_dict=self.gen_feed_dict(batch_size, ebnodb, lr))\n",
        "        return \n",
        "    \n",
        "    def weight_variable(self, shape):\n",
        "        '''Xavier-initialized weights optimized for ReLU Activations'''\n",
        "        (fan_in, fan_out) = shape\n",
        "        low = np.sqrt(6.0/(fan_in + fan_out)) \n",
        "        high = -np.sqrt(6.0/(fan_in + fan_out))\n",
        "        return tf.Variable(tf.random_uniform(shape, minval=low, maxval=high, dtype=tf.float32))\n",
        "    \n",
        "    def bler_sim(self, ebnodbs, batch_size, iterations):\n",
        "        '''Monte Carlo simulations of BLER for a range of Eb/No\n",
        "           Sometimes we to compute statistics for batch sizes that do not fit into the GPUs memory.\n",
        "           You can average over multiple batches with small size instead.           \n",
        "        '''\n",
        "        BLER = np.zeros_like(ebnodbs)\n",
        "        for i in range(iterations):\n",
        "            bler = np.array([self.sess.run(self.vars['bler'],\n",
        "                            feed_dict=self.gen_feed_dict(batch_size, ebnodb, lr=0)) for ebnodb in ebnodbs])\n",
        "            BLER = BLER + bler/iterations\n",
        "        return BLER\n",
        "    \n",
        "    def plot_bler(self, EbNodB, BLER):\n",
        "        '''Plot a BLER curve'''\n",
        "        image = plt.figure(figsize=(10,8))\n",
        "        plt.plot(EbNodB, BLER, '-r', linewidth=2.0)\n",
        "        plt.yscale('log')\n",
        "        plt.xlabel('EbNo (dB)', fontsize=18)\n",
        "        plt.ylabel('Block-error rate', fontsize=18)\n",
        "        plt.grid(True)\n",
        "        plt.ylim([1e-5,1])\n",
        "        return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjh_J3MIlyrF"
      },
      "source": [
        "train_EbNodB = 40\n",
        "val_EbNodB = train_EbNodB\n",
        "\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "training_params = [\n",
        "    #batch_size, lr, ebnodb, iterations\n",
        "    [10000 , lr, train_EbNodB, 1000]\n",
        "    ]\n",
        "\n",
        "validation_params = [\n",
        "    #batch_size, ebnodb, val_steps \n",
        "    [10000, val_EbNodB, 1000],\n",
        "    [10000, val_EbNodB, 1000],\n",
        "    [10000, val_EbNodB, 1000]\n",
        "    ]\n",
        "\n",
        "model_file = 'models/ae_k_{}_n_{}'.format(k,n)\n",
        "ae_Weighted = AE_Weighted(k,n,seed)\n",
        "ae_Weighted.train(training_params, validation_params)\n",
        "ae_Weighted.save(model_file);\n",
        "ae_Weighted = AE_Weighted(k,n,seed, filename=model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsoF-I7Rf7hy"
      },
      "source": [
        "### Plot of learned constellations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjGW8S_df7h0"
      },
      "source": [
        "import itertools\n",
        "def plot_constellation_2(ae, arr, maxrange=None):\n",
        "        '''Generate a plot of the current constellation'''\n",
        "        x = ae.transmit(arr)\n",
        "        #marker = itertools.cycle(('1', '2', '3', '4', '^', '6', '7', '8'))\n",
        "        weights = [1,4,9,16,25,36,49,64]\n",
        "        #weights = [1,1,1,1,1,1,1,1]\n",
        "        #weights = [1,8,27,64,125,216,343,512]\n",
        "        #weights = [1,2,3,4,5,6,7,8]\n",
        "        #weights = [1,16,81,256,625, 1296, 2401, 4096]\n",
        "        #weights = [1,256,6561,65536, 390625, 1.6, 5.7, 16.7]\n",
        "        #x = ae.transmit(np.ones(ae.M)*n)\n",
        "        #print(ae.M)\n",
        "        if (maxrange is None):\n",
        "            maxrange = np.max(np.abs(x))\n",
        "        for k in range(ae.n_complex):\n",
        "            \n",
        "#            image = plt.figure(figsize=(6,6))\n",
        "            image = plt.plot()\n",
        "            plt.grid(True)\n",
        "            plt.xlim(-2,2)\n",
        "            plt.ylim(-2,2)\n",
        "            #plt.show() \n",
        "            #plt.ion()\n",
        "            xshape = np.shape(x)\n",
        "            for i in range(xshape[0]):      \n",
        "                plt.scatter(x[i,k,0],x[i,k,1],c=\"black\")\n",
        "                plt.annotate(weights[i], (x[i,k,0],x[i,k,1]))\n",
        "\n",
        "\n",
        "                #plt.show()              \n",
        "                #plt.pause(1)\n",
        "                #plt.hold(True)\n",
        "            #image.axes[0].set_xticks(np.array([-2,-1,0,1,2]))\n",
        "            #image.axes[0].set_yticks(np.array([-2,-1,0,1,2]))\n",
        "            #image.suptitle('%d. complex symbol' % (k+1))\n",
        "            #image.canvas.draw()\n",
        "            #image.canvas.flush_events()\n",
        "            \n",
        "            plt.xlabel('Re')\n",
        "            plt.ylabel('Im')\n",
        "            #time.sleep(0.1)\n",
        "        return x, image\n",
        "\n",
        "#plot_constellation_2(ae,range(0,ae.M))\n",
        "plot_constellation_2(ae_Weighted, range(0, ae_Weighted.M))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMbROTHNMa79"
      },
      "source": [
        "**THE RMSE Calculations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7-W-Be2auJV"
      },
      "source": [
        "def rmse(predictions,targets):\n",
        "  return np.sqrt((np.subtract(predictions,targets) ** 2).mean())   \n",
        "\n",
        "tr_hat = ae.end2end(len(tr), 40, tr)\n",
        "print(np.shape(tr))\n",
        "print(np.shape(tr_hat))\n",
        "print(tr_hat)\n",
        "\n",
        "\n",
        "tr_hat_w = ae_Weighted.end2end(len(tr), 7, tr)\n",
        "\n",
        "rmse_uw_0 = rmse(([tr_hat[x] for x in s_ind_0]), ([tr[x] for x in s_ind_0]))\n",
        "rmse_uw_1 = rmse(([tr_hat[x] for x in s_ind_1]), ([tr[x] for x in s_ind_1]))\n",
        "rmse_uw_2 = rmse(([tr_hat[x] for x in s_ind_2]), ([tr[x] for x in s_ind_2]))\n",
        "rmse_uw_3 = rmse(([tr_hat[x] for x in s_ind_3]), ([tr[x] for x in s_ind_3]))\n",
        "rmse_uw_4 = rmse(([tr_hat[x] for x in s_ind_4]), ([tr[x] for x in s_ind_4]))\n",
        "rmse_uw_5 = rmse(([tr_hat[x] for x in s_ind_5]), ([tr[x] for x in s_ind_5]))\n",
        "rmse_uw_6 = rmse(([tr_hat[x] for x in s_ind_6]), ([tr[x] for x in s_ind_6]))\n",
        "rmse_uw_7 = rmse(([tr_hat[x] for x in s_ind_7]), ([tr[x] for x in s_ind_7]))\n",
        "\n",
        "\n",
        "rmse_w_0 = rmse(([tr_hat_w[x] for x in s_ind_0]), ([tr[x] for x in s_ind_0]))\n",
        "rmse_w_1 = rmse(([tr_hat_w[x] for x in s_ind_1]), ([tr[x] for x in s_ind_1]))\n",
        "rmse_w_2 = rmse(([tr_hat_w[x] for x in s_ind_2]), ([tr[x] for x in s_ind_2]))\n",
        "rmse_w_3 = rmse(([tr_hat_w[x] for x in s_ind_3]), ([tr[x] for x in s_ind_3]))\n",
        "rmse_w_4 = rmse(([tr_hat_w[x] for x in s_ind_4]), ([tr[x] for x in s_ind_4]))\n",
        "rmse_w_5 = rmse(([tr_hat_w[x] for x in s_ind_5]), ([tr[x] for x in s_ind_5]))\n",
        "rmse_w_6 = rmse(([tr_hat_w[x] for x in s_ind_6]), ([tr[x] for x in s_ind_6]))\n",
        "rmse_w_7 = rmse(([tr_hat_w[x] for x in s_ind_7]), ([tr[x] for x in s_ind_7]))\n",
        "\n",
        "\n",
        "\n",
        "rmse_uw = [rmse_uw_0, rmse_uw_1, rmse_uw_2, rmse_uw_3, rmse_uw_4, rmse_uw_5, rmse_uw_6, rmse_uw_7]\n",
        "rmse_w = [rmse_w_0, rmse_w_1, rmse_w_2, rmse_w_3, rmse_w_4, rmse_w_5, rmse_w_6, rmse_w_7]\n",
        "message = [0,1,2,3,4,5,6,7]\n",
        "\n",
        "plt.plot(message, rmse_uw, '-o');\n",
        "plt.plot(message, rmse_w, '-*');\n",
        "plt.xlabel('Message Bit')\n",
        "plt.ylabel('RMSE')\n",
        "print(rmse_uw_0)\n",
        "plt.legend(['Unweighted', 'Weighted(^2)'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxostCb-vY1i"
      },
      "source": [
        "ae.plot_constellation();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtoc7OKCUgko"
      },
      "source": [
        "# 8-PSK Modulation\n",
        "#8PSK constellation \n",
        "#Demodulation matrx\n",
        "#Qfunction \n",
        "\n",
        "import numpy as np\n",
        "from scipy import special\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import subprocess\n",
        "import shlex\n",
        "\n",
        "\n",
        "#Generating constellation points\n",
        "s = np.zeros((8,2))\n",
        "s_comp = np.zeros((8,1))+1j*np.zeros((8,1))\n",
        "for i in range(8):\n",
        "\ts[i,:] = np.array(([np.cos(i*2*np.pi/8),np.sin(i*2*np.pi/8)])) #vector\n",
        "\ts_comp[i] = s[i,0]+1j*s[i,1] #equivalent complex number\n",
        "\n",
        "#Generating demodulation matrix\n",
        "A = np.zeros((8,2,2))\n",
        "A[0,:,:] = np.array(([np.sqrt(2)-1,1],[np.sqrt(2)-1,-1]))\n",
        "A[1,:,:] = np.array(([np.sqrt(2)+1,-1],[-(np.sqrt(2)-1),1]))\n",
        "A[2,:,:] = np.array(([-(np.sqrt(2)+1),1],[np.sqrt(2)+1,1]))\n",
        "A[3,:,:] = np.array(([np.sqrt(2)-1,1],[-(np.sqrt(2)+1),-1]))\n",
        "A[4,:,:] = np.array(([-(np.sqrt(2)-1),-1],[-(np.sqrt(2)-1),1]))\n",
        "A[5,:,:] = np.array(([-(np.sqrt(2)+1),1],[np.sqrt(2)-1,-1]))\n",
        "A[6,:,:] = np.array(([np.sqrt(2)+1,-1],[-(np.sqrt(2)+1),-1]))\n",
        "A[7,:,:] = np.array(([-(np.sqrt(2)-1),-1],[np.sqrt(2)+1,1]))\n",
        "\n",
        "#Gray code\n",
        "gray = np.zeros((8,3))\n",
        "gray[0,:] = np.array(([0,0,0]))\n",
        "gray[1,:] = np.array(([0,0,1]))\n",
        "gray[2,:] = np.array(([0,1,1]))\n",
        "gray[3,:] = np.array(([0,1,0]))\n",
        "gray[4,:] = np.array(([1,1,0]))\n",
        "gray[5,:] = np.array(([1,1,1]))\n",
        "gray[6,:] = np.array(([1,0,1]))\n",
        "gray[7,:] = np.array(([1,0,0]))\n",
        "\n",
        "\n",
        "#Q-function\n",
        "def qfunc(x):\n",
        "\treturn 0.5*special.erfc(x/np.sqrt(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LDujO11Ulo5"
      },
      "source": [
        "def decode(vec_comp):\n",
        "\tvec = np.zeros((2,1))\n",
        "\tvec[0] = np.real(vec_comp)\n",
        "\tvec[1] = np.imag(vec_comp)\n",
        "\tfor i in range(8):\n",
        "\t\ty = A[i,:,:]@vec\n",
        "\t\tif (y [0] >= 0) and (y[1] >= 0):\n",
        "\t\t\treturn s_comp[i]\n",
        "\n",
        "#Extracting bits from demodulated symbols\n",
        "def detect(vec_comp):\n",
        "\tvec = np.zeros((2,1))\n",
        "\tvec[0] = np.real(vec_comp)\n",
        "\tvec[1] = np.imag(vec_comp)\n",
        "\tfor i in range(8):\n",
        "\t\tif s[i,0]==vec[0] and s[i,1] == vec[1]:\n",
        "\t\t\treturn gray[i,:]\n",
        "\n",
        "#Demodulating symbol stream from received noisy  symbols\n",
        "def rx_symb(mat):\n",
        "\tlen = mat.shape[1]\n",
        "\trx_symb_stream = []\n",
        "\tfor i in range(len):\n",
        "\t\trx_symb_stream.append(decode(mat[:,i]))\n",
        "\treturn rx_symb_stream\n",
        "\n",
        "#Getting received bit stream from demodulated symbols\n",
        "def rx_bit(mat):\n",
        "\tlen = mat.shape[1]\n",
        "\trx_bit_stream = []\n",
        "\tfor i in range(len):\n",
        "\t\trx_bit_stream.append(detect(mat[:,i]))\n",
        "\treturn rx_bit_stream"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPu3HX_SUov_"
      },
      "source": [
        "#Generates a bitstream\n",
        "def bitstream(n):\n",
        "\treturn np.random.randint(0,2,n)\n",
        "\n",
        "#Converts bits to 8-PSK symbols using gray code\n",
        "def mapping(b0,b1,b2):\n",
        "\tif (b0 == 0 and b1 == 0 and b2 == 0):\n",
        "\t\treturn s[0,:]\n",
        "\telif (b0 == 0 and b1 == 0 and b2 == 1):\n",
        "\t\treturn s[1,:]\n",
        "\telif (b0 == 0 and b1 == 1 and b2 == 1):\n",
        "\t\treturn s[2,:]\n",
        "\telif (b0 == 0 and b1 == 1 and b2 == 0):\n",
        "\t\treturn s[3,:]\n",
        "\telif( b0 == 1 and b1 == 1 and b2 == 0):\n",
        "\t\treturn s[4,:]\n",
        "\telif(b0==1 and b1 == 1 and b2 == 1):\n",
        "\t\treturn s[5,:]\n",
        "\telif(b0==1 and b1 == 0 and b2 == 1):\n",
        "\t\treturn s[6,:]\n",
        "\telif(b0==1 and b1 == 0 and b2 == 0):\n",
        "\t\treturn s[7,:]\n",
        "\n",
        "\n",
        "#Converts bitstream to 8-PSK symbol stream\n",
        "def symb(bits):\n",
        "\tsymbol =[]\n",
        "\ti = 0\n",
        "\twhile(1):\n",
        "\t\ttry:\n",
        "\t\t\tsymbol.append(mapping(bits[i],bits[i+1],bits[i+2]))\n",
        "\t\t\ti = i+3\n",
        "\t\texcept IndexError:\n",
        "\t\t\treturn symbol\n",
        "\n",
        "#Converts bitstream to 8-PSK complex symbol stream\n",
        "def CompSymb(bits):\n",
        "\tsymbols_lst = symb(bits)\n",
        "\tsymbols = np.array(symbols_lst).T #Symbol vectors\n",
        "\tsymbols_comp = symbols[0,:]+1j*symbols[1,:] #Equivalent complex symbols\n",
        "\treturn symbols_comp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPNtUtWBUryp"
      },
      "source": [
        "\n",
        "#SNR range\n",
        "snrlen=15\n",
        "\n",
        "#SNR in dB and actual per bit \n",
        "#(Check Proakis for factor of 6)\n",
        "snr_db = np.linspace(0,snrlen,snrlen)\n",
        "snr = 6*10**(0.1*snr_db)\n",
        "\n",
        "#Bitstream size\n",
        "bitsimlen = 99999\n",
        "\n",
        "#Symbol stream size\n",
        "simlen = bitsimlen //3\n",
        "\n",
        "#Generating bitstream\n",
        "bits = bitstream(bitsimlen)\n",
        "\n",
        "#Converting bits to Gray coded 8-PSK symbols\n",
        "#Intermediate steps  required for converting list to\n",
        "#numpy matrix\n",
        "symbols_lst = symb(bits)\n",
        "symbols = np.array(symbols_lst).T #Symbol vectors\n",
        "symbols_comp = symbols[0,:]+1j*symbols[1,:] #Equivalent complex symbols\n",
        "\n",
        "ser =[]\n",
        "ser_anal=[]\n",
        "ber = []\n",
        "\n",
        "#SNRloop\n",
        "for k in range(0,snrlen):\n",
        "\treceived = []\n",
        "\tt=0\n",
        "\t#Complex noise\n",
        "\tnoise_comp = np.random.normal(0,1,simlen)+1j*np.random.normal(0,1,simlen)\n",
        "\t#Generating complex received symbols\n",
        "  #fade_comp = np.random.normal(0,1,simlen)+1j*np.random.normal(0,1,simlen)\n",
        "  #fade_comp = np.abs(fade_comp)\n",
        "  #fade_comp = np.math.sqrt(1/2)*fade_comp\n",
        "\ty_comp = np.sqrt(snr[k])*symbols_comp +noise_comp\n",
        "\tbrx = []\n",
        "\tfor i in range(simlen):\n",
        "\t\tsrx_comp = decode(y_comp[i]) #Received Symbol\n",
        "\t\tbrx.append(detect(srx_comp))  #Received Bits\n",
        "\t\tif symbols_comp[i]==srx_comp:\n",
        "\t\t\tt+=1; #Counting symbol errors\n",
        "\t#Evaluating SER\n",
        "\tser.append(1-(t/33334.0))\n",
        "\tser_anal.append(2*qfunc((np.sqrt(snr[k]))*np.sin(np.pi/8)))\n",
        "\t#Received bitstream\n",
        "\tbrx=np.array(brx).flatten()\n",
        "\t#Evaluating BER\n",
        "\tbit_diff = bits-brx\n",
        "\tber.append(1-len(np.where(bit_diff == 0)[0])/bitsimlen)\n",
        "\n",
        "\n",
        "\n",
        "#Plots\n",
        "plt.semilogy(snr_db,ser_anal,label='SER Analysis')\n",
        "plt.semilogy(snr_db,ser,'o',label='SER Sim')\n",
        "plt.semilogy(snr_db,ber,label='BER Sim')\n",
        "plt.xlabel('SNR$\\\\left(\\\\frac{E_b}{N_0}\\\\right)$')\n",
        "plt.ylabel('$P_e$')\n",
        "plt.legend()\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFZCQNe9f7iD"
      },
      "source": [
        "### BLER Simulations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wukzCBJff7iE"
      },
      "source": [
        " ebnodbs = np.linspace(0,14,15)\n",
        "BLER_8PSK = [0.3478959, 0.2926128, 0.2378847, 0.1854187, 0.1372344, 0.0953536, 0.0614003, 0.0360195, 0.0185215, 0.0082433, 0.0030178, 0.0008626, 0.0001903, 0.0000289, 0.0000027, ]\n",
        "blers = ae.bler_sim(ebnodbs, 1000000, 1);\n",
        "ae.plot_bler(ebnodbs, blers);\n",
        "blers_w = ae_Weighted.bler_sim(ebnodbs, 1000000, 1);\n",
        "#ae_Weighted.plot_bler(ebnodbs, blers_w);\n",
        "plt.plot(ebnodbs, blers_w)\n",
        "plt.semilogy(snr_db,ser,'o')\n",
        "plt.plot(ebnodbs,BLER_8PSK);\n",
        "plt.legend(['Autoencoder (Rayleigh+AWGN)', 'Weighted Autoencoder(Rayleigh+AWGN)', 'SER Sim(AWGN)', '8PSK(AWGN)'], prop={'size': 16}, loc='lower left');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMl-Rljrf7iR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}